---
title: "Colombia COVID-19 - Central region"
author: "Angela Carraro, Giullia Monteiro Milano Oliveira, Gaia Saveri"
date: "28/07/2020"
output:
  rmdformats::readthedown:
  html_document:
    highlight: kate
    lightbox: true
    gallery: true
    toc: yes
    toc_depth: 3
  include: null
  ioslides_presentation:
    # “default”, “cerulean”, “journal”, “flatly”, “darkly”, “readable”, “spacelab”, “united”, “cosmo”, “lumen”, “paper”, “sandstone”, “simplex”, “yeti”
    highlight: kate
    theme: "sandstone"
    colortheme: "sandstone"
    lightbox: true
    widescreen: true
    smaller: true
    logo: Logo_units_blu.png #logo_dssc_alt.png
  pdf_document:
    highlight: kate
    keep_tex: yes
    toc: yes
  slidy_presentation:
    fig.height: 3
    fig.width: 4
    highlight: kate
  beamer_presentation:
    highlight: tango
    theme: "metropolis"
    colortheme: "metropolis"
    fonttheme: "structurebold"
    #always_allow_html: true
  slide_level: 2
header-includes:
- \usepackage{color}
- \definecolor{Purple}{HTML}{911146}
- \definecolor{Orange}{HTML}{CF4A30}
- \setbeamercolor{alerted text}{fg=Orange}
- \setbeamercolor{frametitle}{bg=Purple}
institute: University of Trieste
graphics: yes
fontsize: 8pt
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center', warning=FALSE, message=FALSE, fig.asp=0.625, dev='png', global.par = TRUE, dev.args=list(pointsize=10), fig.path = 'figs/')
```

```{r setup, include=FALSE}
library(knitr)
local({
  hook_plot = knit_hooks$get('plot')
  knit_hooks$set(plot = function(x, options) {
    paste0('\n\n----\n\n', hook_plot(x, options))
  })
})
knitr::opts_chunk$set(echo = FALSE)#, tidy = TRUE)
```

```{r message=FALSE, include=FALSE}
library(MASS)
library(readr)
library(dplyr)
library(ggplot2)
library(bayesplot)
library(ggthemes)
library(ggrepel)
library(RColorBrewer)
library(leaflet)
library(geojsonio)
library(htmltools)
library(htmlwidgets)
library(rstan)
library(lubridate)
```

## Our project

We decided to do **central Colombia**, basically because it is where the capital is.

We built a model for the number of `confirmed` cases using all the others covariates (plus some we created) and we estimated the predictive accuracy of our selected model.

We decided to consider as **central Colombia** the following departments/districts: Bogotà DC, Boyacá, Tolima, Cundinamarca, Meta, Quindío, Valle del Cauca, Risaralda, Celdas, Boyacá, Antioquia, Santander, Casanare.

## Loading the dataset

This dataset is missing completely the department `Valle del Cauca`!

```{r loading, echo=TRUE}
colombia_covid <- as.data.frame(read_csv("data/covid19co.csv"))
cols <- colnames(colombia_covid)[c(1, 4, 5, 6, 7, 8, 9, 11, 14)]
colombia_covid <- colombia_covid[cols]
colombia_covid <- colombia_covid[, c(1, 9, 2, 3, 4, 5, 6, 7, 8)]
colnames(colombia_covid) <- c("ID de caso", "Fecha de diagnóstico", "Ciudad de ubicación", "Departamento o Distrito", "Atención", "Edad" , "Sexo", "Tipo", "País de procedencia")
#colombia_covid$`Departamento o Distrito`[which(colombia_covid$`Departamento o Distrito` == "Valle Del Cauca")] <- "Valle del Cauca"
central.colombia.dep <- c("Bogotá D.C.", "Tolima", "Cundinamarca", "Meta", "Boyacá", "Quindío", "Cauca",
    "Valle del Cauca", "Risaralda", "Caldas", "Boyacá", "Antioquia", "Santander", "Casanare")
central.colombia.rows <- which(colombia_covid$`Departamento o Distrito` %in% central.colombia.dep)
colombia_covid <- colombia_covid[central.colombia.rows, ]
colombia_covid <- colombia_covid[-which(colombia_covid$`Fecha de diagnóstico`== "-"), ]
colombia_covid
```
 
## Description of variables

- **ID de caso**: ID of the confirmed case. 

- **Fecha de diagnóstico**: Date in which the disease was diagnosed. 

- **Ciudad de ubicación**: City where the case was diagnosed.

- **Departamento o Distrito**: Department or district where the city belongs to.

- **Atención**: Situation of the patient: recovered, at home, at the hospital, at the ICU or deceased.

- **Edad**: Age of the confirmed case.

- **Sexo**: Sex of the confirmed case.

- **Tipo**: How the person got infected: in Colombia, abroad or unknown. 

- **País de procedencia**: Country of origin if the person got infected abroad.
 
## Map

Here we can see our selected cities. The color of the pins is related with the number of cases: if they are less than $10$ the color is "green", if they are less than $100$ the color is "orange", otherwise it is "red".

```{r create_gis_df, include=FALSE}
#lat-long
#bogota<c(4.592164298, -74.072166378, 542)
valle_de_cauca<-c("Valle del Cauca", 3.4372200, -76.5225000, 150)
cauca<-c("Cauca", 2.43823, -76.6131592, 763) 
antioquia<-c("Antioquia",6.2518400, -75.5635900, 9042)
cartagena<-c("Cartagena D.T. y C", 10.39972, -75.51444, 39)
huila<-c("Huila", 2.9273, -75.2818909, 30)
meta<-c("Meta", 4.1420000, -73.6266400, 1584)
risaralda<-c("Risaralda", 4.8133302, -75.6961136, 742)
norte_santander<-c("Norte de Santander", 7.8939100, -72.5078200, 21)
caldas<-c("Caldas", 5.0688900, -75.5173800, 302)
cudinamarca<-c("Cundinamarca", 4.862437, -74.058655, 4071)
barraquilla<-c("Barranquilla D.E.", 10.9685400, -74.7813200, 35) #atlantico
santader<-c("Santander", 7.1253900, -73.1198000, 1301)
quindio<-c("Quindío", 4.535000, -75.675690, 194)
tolima<-c("Tolima", 4.43889, -75.2322235, 174)
santa_marta<-c("Santa Marta D.T. y C.", 11.24079, -74.19904, 12)
cesar<-c("Cesar", 10.4631400, -73.2532200, 16)
san_andres<-c("San Andrés", 12.5847197, -81.7005615, 2)
casanare<-c("Casanare", 5.3377500, -72.3958600, 118)
narino<-c("Nariño", 1.2136100, -77.2811100, 6)
boyaca<-c("Boyacá", 5.767222, -72.940651, 485)
cordoba<-c("Córdoba", 8.7479800, -75.8814300, 2)
bolivar<-c("Bolívar", 10.3997200, -75.5144400, 3)
sucre<-c("Sucre", 9.3047199, -75.3977814, 1)
guajira<-c("La Guajira", 11.5444400, -72.9072200, 1)

gis_data<-data.frame(name="Bogotá D.C.", latitude=4.624335, longitude=-74.063644, cases=49605) #bogotà
gis_data$name<-as.character(gis_data$name)
gis_data<-rbind(gis_data, cauca)
gis_data<-rbind(gis_data, valle_de_cauca)
gis_data<-rbind(gis_data, antioquia)
gis_data<-rbind(gis_data, cartagena)
gis_data<-rbind(gis_data, huila)
gis_data<-rbind(gis_data, meta)
gis_data<-rbind(gis_data, risaralda)
gis_data<-rbind(gis_data, norte_santander)
gis_data<-rbind(gis_data, caldas)
gis_data<-rbind(gis_data, cudinamarca)
gis_data<-rbind(gis_data, barraquilla)
gis_data<-rbind(gis_data, santader)
gis_data<-rbind(gis_data, quindio)
gis_data<-rbind(gis_data, tolima)
gis_data<-rbind(gis_data, santa_marta)
gis_data<-rbind(gis_data, cesar)
gis_data<-rbind(gis_data, san_andres)
gis_data<-rbind(gis_data, casanare)
gis_data<-rbind(gis_data, narino)
gis_data<-rbind(gis_data, boyaca)
gis_data<-rbind(gis_data, cordoba)
gis_data<-rbind(gis_data, bolivar)
gis_data<-rbind(gis_data, sucre)
gis_data<-rbind(gis_data, guajira)

gis_data$latitude<-as.numeric(gis_data$latitude)
gis_data$longitude<-as.numeric(gis_data$longitude)
gis_data$cases<-as.numeric(gis_data$cases)
```

```{r central_colombia, inlcude=FALSE}
dept<-geojsonio::geojson_read("data/Colombia.geo.json", what="sp")
#slice the gis_data dataset
central_gis_data<-gis_data[which(gis_data$name %in% central.colombia.dep),]
#slice the geojson dataset 
central_dept<-c("SANTAFE DE BOGOTA D.C", "TOLIMA", "CUNDINAMARCA", "META", "BOYACA", "QUINDIO", "CAUCA", "VALLE DEL CAUCA", "RISARALDA", "CALDAS", "BOYACA", "ANTIOQUIA", "SANTANDER", "CASANARE")
central.dept<-dept[which(dept@data$NOMBRE_DPT %in% central_dept),]
```

```{r our_map, echo=TRUE, warning=FALSE, include=FALSE}
getColor <- function(central_gis_data) {
  sapply(central_gis_data$cases, function(cases) {
  if(cases <= 500) {
    "green"
  } else if(cases>501 & cases <= 5000) {
    "orange"
  } else {
    "red"
  } })
}

icons <- awesomeIcons(
  icon = 'ios-close',
  iconColor = 'black',
  library = 'ion',
  markerColor = getColor(central_gis_data)
)

#now colombia is yellow and our departments are red

central_map <- leaflet(data=central_gis_data) %>% addTiles() %>%
  addAwesomeMarkers(~longitude, ~latitude, icon=icons, label = ~htmlEscape(paste(name,cases,sep=" : "))) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data=dept,
              opacity=0.1,
              color="yellow",
              fillOpacity = 0.1) %>%
  addPolygons(data=central.dept,     
              opacity = 0.2,
              color = "red",
              dashArray = "3",
              fillOpacity = 0.1)
#saveWidget(central_map, file="figs/central_colombia.html")
```

```{r map}
central_map
```


## Preprocessing {.smaller}

```{r types, include=FALSE}
## day column in "international" format (so that R can fix the sorting properly)
colombia_covid$`Fecha de diagnóstico` <- as.Date(colombia_covid$`Fecha de diagnóstico`, format="%d/%m/%Y")
colombia_covid <- colombia_covid[order(colombia_covid$`Fecha de diagnóstico`), ]
# there were missing rows since we cancelled some departments
colombia_covid$`ID de caso` <- 1:dim(colombia_covid)[1]
colombia_covid <- colombia_covid %>% mutate("Grupo de edad" = case_when(Edad <= 18 ~ '0_18',
                                                   Edad >= 19  & Edad <= 30 ~ '19_30',
                                                   Edad >=  31 & Edad <= 45 ~ '31_45',
                                                   Edad >= 46 & Edad <= 60 ~ '46_60',
                                                   Edad >=61 & Edad <= 75 ~ '60_75',
                                                   Edad >=76 ~ '76+'))
#colombia_covid$`Grupo de edad` <- as.factor(colombia_covid$`Grupo de edad`)
#colombia_covid$`Departamento o Distrito` <- as.factor(colombia_covid$`Departamento o Distrito`)
#colombia_covid$`Ciudad de ubicación` <- as.factor(colombia_covid$`Ciudad de ubicación`)
#colombia_covid$Sexo <- as.factor(colombia_covid$Sexo)
#colombia_covid$Atención <- as.factor(colombia_covid$Atención)
#colombia_covid$Tipo <- as.factor(colombia_covid$Tipo)
```

We had to clean the dataset:

- We transformed the `Fecha de diagnóstico` variable into a `Date` type variable,

- we fixed the variable `Id de caso` (since we removed some departments, so some lines, the numbers weren't consecutive),

- we created a variable `Grupo de edad`,

- we cleaned the column `País de procedencia` (replaced cities with the country) and created the variable `Continente de procedencia` (as the first is too fragmented we thought to consider the continents).

<!-- - we transformed the variables `Grupo de edad`, `Departamento o Distrito`, `Ciudad de ubicación`, `Sexo`, `Atención`, `Tipo` into factors, -->

```{r display}
head(colombia_covid, 3)
```

## New dataset I

```{r cases}
cases <- colombia_covid %>%
  group_by(`Fecha de diagnóstico`) %>%
  count() %>% rename("Date" = `Fecha de diagnóstico`, "New cases/day" = n)
cases2 <- colombia_covid %>%
  group_by(`Fecha de diagnóstico`) %>%
  summarise(`Cumulative cases` = max(`ID de caso`))
cases <- bind_cols(cases, cases2%>%
  dplyr::select(-c(`Fecha de diagnóstico`)))
cases <- as.data.frame(cases)
cases <- cases %>% mutate(BETWEEN0 = as.numeric(difftime(Date, lag(Date, 1), units = "days")),
            BETWEEN = ifelse(is.na(BETWEEN0), 0, BETWEEN0), `Elapsed time` =
              cumsum(as.numeric(BETWEEN))) %>% dplyr::select(-c(BETWEEN0,BETWEEN))
cases <- cases[, c(1,4,2,3)]
```

```{r cases_head, echo=FALSE}
head(cases, 10)
cases
```

## New dataset II

```{r cases_per_dep}
cases_dep <- colombia_covid %>%
  group_by(`Fecha de diagnóstico`, `Departamento o Distrito`) %>%
  count() %>% rename("Date" = `Fecha de diagnóstico`, "Department"=`Departamento o Distrito`, "New cases/day" = n)
cases_dep <- cases_dep %>%
  group_by(`Department`) %>%
  mutate(`Cumulative cases/Department` = cumsum(`New cases/day`))
cases_dep <- as.data.frame(cases_dep)
cases_dep <- cases_dep %>% mutate(BETWEEN0 = as.numeric(difftime(Date, lag(Date, 1), units = "days")),
            BETWEEN = ifelse(is.na(BETWEEN0), 0, BETWEEN0), `Elapsed time` =
            cumsum(as.numeric(BETWEEN))) %>% dplyr::select(-c(BETWEEN0,BETWEEN))
```


```{r fix_dataset, warning=FALSE, include=FALSE}
cases_dep <- cases_dep[order(cases_dep$Department) ,]
cases_dep <- cases_dep %>%
  dplyr::mutate(dep_idx = factor(Department, levels=unique(Department)),
         `Department ID` = as.integer(dep_idx)) %>%
  dplyr::select(-dep_idx)
cases_dep <- cases_dep[, c(1, 5, 2, 6, 3, 4)]

mean_age <- colombia_covid %>%
  group_by(`Departamento o Distrito`, `Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(`Mean age` = mean(., na.rm=TRUE)))

cases_dep <- cbind(cases_dep, `Mean age` = mean_age$`Mean age`)
```

```{r}
head(cases_dep, 10)
cases_dep
#head(cases_dep[order(cases_dep$Date), ], 10)
#cases_dep[c(1, 118, 243, 321, 401, 444, 526, 641, 736, 805), ]
```

```{r relevant_dep, include=FALSE}
#departments with more than 30 cases:
relevant <- unique(cases_dep[cases_dep$`Cumulative cases/Department`>30,]$Department)
cases_relev_dep <- as.data.frame(subset(cases_dep, Department %in% relevant))
cases_relev_dep <- cases_relev_dep[order(cases_relev_dep$Department), ]
row.names(cases_relev_dep) <- seq(1:nrow(cases_relev_dep))
```

```{r cases_dep_head, eval=FALSE, include=FALSE}
#head(cases_relev_dep)
cases_relev_dep[c(1, 2, 16, 17, 18, 40, 41, 42, 54, 55), ]
```

## Exploring the dataset {.smaller}

Scattered infos about pandemic in Colombia (https://en.wikipedia.org/wiki/COVID-19_pandemic_in_Colombia): 

  * the quarantine started on the 20th of March, since our data are from 6th of March to 2nd of April, it is very likeliy that quarantine effects are not witnessed in our data.
  
  * on March the 26th there was a damage in the machine that prepared the samples for processing and subsequent diagnosis of COVID-19, which affected the speed at which results were being produced. This could explain the very low number of confirmed cases.

```{r cases_dep, echo=FALSE, warning=FALSE}
#group, count, sort and rename
df1 <- colombia_covid %>% group_by(`Departamento o Distrito`) %>% count()%>%arrange(n)%>%rename(`Number of cases`=n)
#Convert x variable into a factor
df1$`Departamento o Distrito` <- factor(df1$`Departamento o Distrito`, levels = df1$`Departamento o Distrito`)

#plotting
theme_set(theme_bw())
plot1 <- ggplot(df1, aes(x=`Departamento o Distrito`, y=`Number of cases`)) + 
  geom_bar(stat="identity", width=.5, fill="tomato3") + 
  labs(title="Number of cases per department") + 
  theme(axis.text.x = element_text(angle=65, vjust=0.6))
plot1
#scale_fill_gradient(low = "white", high = "steelblue")


```

```{r donut, echo=FALSE, warning=FALSE}
#group, count, sort and rename
#df1 <- colombia_covid %>% group_by(`Departamento o Distrito`) %>% count()%>%arrange(n)%>%rename(`Number of cases`=n)
#Convert x variable into a factor
#df1$`Departamento o Distrito` <- factor(df1$`Departamento o Distrito`, levels = df1$`Departamento o Distrito`)
 
# Compute percentages
df1$fraction <- df1$`Number of cases` / sum(df1$`Number of cases`)

# Compute the cumulative percentages (top of each rectangle)
df1$ymax <- cumsum(df1$fraction)

# Compute the bottom of each rectangle
df1$ymin <- c(0, head(df1$ymax, n=-1))
 
# Make the plot
plot2 <- ggplot(df1, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=`Departamento o Distrito`)) +
     geom_rect() +
     coord_polar(theta="y") + 
     xlim(c(2, 4))+
  scale_fill_brewer(palette="Set3")+
  labs(title="Number of cases per department")
plot2

```

<!-- Number of cases confirmed day by day -->

```{r barplot, echo=FALSE, warning=FALSE, fig.pos='htb!'}
theme_set(theme_classic())

colorCount<-length(unique(colombia_covid$`Departamento o Distrito`)) 
getPalette<-colorRampPalette(brewer.pal(12, "Spectral"), bias=1.8)(colorCount)

ggplot(as.data.frame(colombia_covid), aes(x = `Fecha de diagnóstico`)) +
  scale_fill_manual(values = getPalette) +
  geom_histogram(aes(fill=`Departamento o Distrito`), width = 0.8, stat="count") + 
  #guides(fill = guide_legend(reverse = TRUE))+
  theme(axis.text.x = element_text(angle=65, vjust=0.6),
        legend.position = "right") +
  labs(title = "Daily number of confirmed cases", 
       subtitle = "subdivided across departments",
       x = "Date of confirmation",
       fill = "Department")
```

The previous plot represents the daily incidence of the desease across all the departments we are taking into account.

## Other plots

```{r waffle_chart, echo=FALSE, warning=FALSE}
theme_set(theme_classic())
region<-colombia_covid$`Departamento o Distrito`
nrows<-10
df <- expand.grid(y = 1:nrows, x = 1:nrows)
categ_table <- round(table(region) * ((nrows*nrows+1)/(length(region))))
df$category<-factor(rep(names(categ_table), categ_table))
waffle_chart <- ggplot(df, aes(x = x, y = y, fill = df$category)) + 
        geom_tile(color = "black", size = 0.5) +
        scale_x_continuous(expand = c(0, 0)) +
        scale_y_continuous(expand = c(0, 0), trans = 'reverse') +
        scale_fill_brewer(palette = "Set3") +
        labs(title="Frequency of cases across Departments", subtitle="Waffle Chart") + 
        theme(#panel.border = element_rect(size = 2),
        plot.title = element_text(size = rel(1.2)),
              axis.text = element_blank(),
              axis.title = element_blank(),
              axis.ticks = element_blank(),
              legend.title = element_blank(),
              legend.position = "right")
waffle_chart
```

The major number of cases are in the capital Bogotà.

```{r cumulative_plot, echo=FALSE}
ggplot(cases, aes(x=Date, y=`Cumulative cases`)) +
  geom_point(size=3) +
  geom_segment(aes(x=Date,
                   xend=Date,
                   y=0,
                   yend=`Cumulative cases`)) +
  labs(title = "Cumulative number of confirmed cases",
       x = "Date of confirmation") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6))
```

Here the growth seems exponential (and this is consistent with the fact that we are studying the early stages of the outbreak).

```{r gender_plot, echo=TRUE, warning=FALSE}
brks <- seq(-250, 250, 50)
lbls <- as.character(c(seq(-250, 0, 50), seq(50, 250, 50)))

ggplot(data=colombia_covid, aes(x=`Departamento o Distrito`, fill = Sexo)) +  
                              geom_bar(data = subset(colombia_covid, Sexo == "F")) +
                              geom_bar(data = subset(colombia_covid, Sexo == "M"), aes(y=..count..*(-1))) + 
                              scale_y_continuous(breaks = brks,
                                               labels = lbls) + 
                              coord_flip() +  
                              labs(title="Spread of the desease across genders",
                                   y = "Number of cases",
                                   x = "Department",
                                   fill = "Gender") +
                              theme_tufte() +  
                              theme(plot.title = element_text(hjust = .5), 
                                    axis.ticks = element_blank()) +   
                              scale_fill_brewer(palette = "Dark3")  
```

The desease (number of cases) is more or less equally distributed across genders.

```{r age_grps_plot, echo=TRUE, warning=FALSE}
#compute percentage so that we can label more precisely the pie chart
age_groups_pie <- colombia_covid %>% 
  group_by(`Grupo de edad`) %>%
  count() %>%
  ungroup() %>%
  mutate(per=`n`/sum(`n`)) %>% 
  arrange(desc(`Grupo de edad`))
age_groups_pie$label <- scales::percent(age_groups_pie$per)

age_pie <- ggplot(age_groups_pie, aes(x = "", y = per, fill = factor(`Grupo de edad`))) + 
  geom_bar(stat="identity", width = 1) +
  theme(axis.line = element_blank(), 
        plot.title = element_text(hjust=0.5)) + 
  labs(fill="Age groups", 
       x=NULL, 
       y=NULL, 
       title="Distribution of the desease across ages") +
  coord_polar(theta = "y") +
  #geom_text(aes(x=1, y = cumsum(per) - per/2, label=label))
  geom_label_repel(aes(x=1, y=cumsum(per) - per/2, label=label), size=3, show.legend = F, nudge_x = 0) +
  guides(fill = guide_legend(title = "Group"))
  
age_pie 
```

People from 31 to 45 years old are the most affected by the disease and people over 76 years old are the least affected.
Colombia is a very young country. In 2018 the median age of the population was 30.4 years old and the largest age group is made of people from 25 to 54 years old, which comprises 41.98% of the population.
(https://www.indexmundi.com/colombia/demographics_profile.html)

## Age-Sex plot

```{r age-sex_plot, echo=FALSE, warning=FALSE}
keep <- c("Sexo", "Grupo de edad")
age_groups<-colombia_covid$`Grupo de edad`[names(colombia_covid$`Grupo de edad`)%in%keep]
age_groups_count <- aggregate(cbind(pop=Sexo) ~ `Grupo de edad` + Sexo,
                      data=colombia_covid,
                      FUN = function(x){NROW(x)})
age_groups_count$count <- ifelse(age_groups_count$Sexo == "F", age_groups_count$pop * -1, age_groups_count$pop)
age_groups_count<-as.data.frame(age_groups_count[names(age_groups_count)!="pop"])

ggplot(age_groups_count, aes(x=`Grupo de edad`, y=count, fill=Sexo)) +
  geom_col() + 
  #facet_share(~Sexo, dir = "h") +
  coord_flip(clip="off") +
  theme_minimal() +
  labs(title = "Distribution of sex by age",
       y = "",
       x = "Age group")
```

There isn’t much difference between the sexes among the different group of ages.

## Tipo plot

```{r tipo_plot, echo=TRUE, warning=FALSE}
theme_set(theme_classic())

ggplot(colombia_covid, aes(x = `Fecha de diagnóstico`)) +
  scale_fill_brewer(palette = "Set3") +
  geom_histogram(aes(fill=Tipo), width = 0.8, stat="count") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6)) +
  labs(title = "Daily number of confirmed cases", 
       subtitle = "subdivided across type",
       x = "Date of confirmation",
       fill = "Type")
```

## Tipo

I think that `en estudio` means that it is not clear while the case is imported or not, however it seems like there are more imported cases, we can count them:

```{r tipo2, echo=TRUE, warning=FALSE}
type_pie <- colombia_covid %>% 
  group_by(Tipo) %>%
  count() %>%
  ungroup() %>%
  mutate(per=`n`/sum(`n`)) %>% 
  arrange(desc(Tipo))
type_pie$label <- scales::percent(type_pie$per)
type_pie<-type_pie[names(type_pie)!="per"]
colnames(type_pie)<-c("Tipo", "Total number", "Percentage")
type_pie
```

<!-- ## Continent

Now let's plot a pie chart to be able to see the distribution of cases across the continents.  -->

<!-- ```{r country2, warning=FALSE, include=FALSE} -->
<!-- unique(colombia_covid$`Continente de procedencia`) -->
<!-- #Some observations came from more than one continent. So these observations we will assign them as "more than one continent" -->
<!-- #change the `Continente de procedencia` columns  (didn't modify the original dataset though) -->
<!-- continent_of_origin <- colombia_covid -->
<!-- continent_of_origin$`Continente de procedencia`[continent_of_origin$`Continente de procedencia`=="Europa - Asia"] <- "More than one continent" -->
<!-- continent_of_origin$`Continente de procedencia`[continent_of_origin$`Continente de procedencia`=="Europa - África"] <- "More than one continent" -->
<!-- continent_of_origin$`Continente de procedencia`[continent_of_origin$`Continente de procedencia`=="Europa - Centroamérica"] <- "More than one continent" -->
<!-- continent_of_origin$`Continente de procedencia`[continent_of_origin$`Continente de procedencia`=="Asia - África"] <- "More than one continent" -->
<!-- unique(continent_of_origin) -->

<!-- # compute percentage so that we can label more precisely the pie chart -->
<!-- continents_pie <- continent_of_origin %>% group_by(`Continente de procedencia`) %>% count() %>% ungroup() %>%  -->
<!--   mutate(per = n/sum(n)) %>% arrange(desc(`Continente de procedencia`)) -->
<!-- continents_pie$label <- scales::percent(continents_pie$per) -->

<!-- cont_pie <- ggplot(continents_pie, aes(x = "", y = per, fill = factor(`Continente de procedencia`))) +  -->
<!--   geom_bar(stat = "identity", width = 1) + theme(axis.line = element_blank(),  -->
<!--                                                  plot.title = element_text(hjust = 0.5)) + labs(fill = "Continents", x = NULL,  -->
<!--                                                                                                 y = NULL, title = "Distribution of the desease across infection location") + coord_polar(theta = "y") +  -->
<!--   # geom_text(aes(x=1, y = cumsum(per) - per/2, label=label)) -->
<!--   geom_label_repel(aes(x = 1, y = cumsum(per) - per/2, label = label), size = 3,  -->
<!--                    show.legend = F, nudge_x = 0) + guides(fill = guide_legend(title = "Group")) -->
<!-- ``` -->

<!-- ```{r country_plot} -->
<!-- cont_pie -->
<!-- ``` -->

The majority of the cases in the country are people that got infected inside Colombia. Then, people that contracted the disease abroad came mainly from Europe, followed by North America and Central America. 

```{r function, include=FALSE}
predict.confidence <- function(object, newdata, level = 0.95, ...) {
    if (!is(object, "glm")) {
        stop("Model should be a glm")
    }
    if (!is(newdata, "data.frame")) {
        stop("Plase input a data frame for newdata")
    }
    if (!is.numeric(level) | level < 0 | level > 1) {
        stop("level should be numeric and between 0 and 1")
    }
    ilink <- family(object)$linkinv
    ci.factor <- qnorm(1 - (1 - level)/2)
    # calculate CIs:
    fit <- predict(object, newdata = newdata, level = level, 
                    type = "link", se.fit = TRUE, ...)
    lwr <- ilink(fit$fit - ci.factor * fit$se.fit)
    upr <- ilink(fit$fit + ci.factor * fit$se.fit)
    df <- data.frame("fit" = ilink(fit$fit), "lwr" = lwr, "upr" = upr)
    return(df)
}
```

# Correlation between the categorical variables

We used Cramer's V to calculate the correlation between our categorical variables. 

```{r cramer, echo=TRUE, warning=FALSE}
library(data.table) # data mgmt
library(gtools) # combination
library(plotly) # interactive graphics
cramervdata <- colombia_covid %>% select(`Ciudad de ubicación`,`Departamento o Distrito`,Atención,Sexo,Tipo,`País de procedencia`,`Grupo de edad`)
cramervdata[] <- lapply(cramervdata, factor)
cramervdata <- as.data.table(cramervdata)
cat_var <- colnames(cramervdata)

# Function to compute Cramer's V
# https://www.r-bloggers.com/example-8-39-calculating-cramers-v/
cv.test = function(x,y) {
  CV = sqrt(chisq.test(x, y, correct=FALSE)$statistic /
              (length(x)[1] * (min(length(unique(x))[1],length(unique(y))[1]) - 1)))
  return(as.numeric(CV))
}

# Apply the function to the combination of categorical variable
v_cramer_all <- function(cat_var, df){
  cat_var_grid <- data.table(combinations(n = length(cat_var), r = 2, v = cat_var, repeats.allowed = FALSE))
  
  do.call(rbind,
          apply(cat_var_grid, 1, function(x){
            tmp <- as.character(x)
            vec1 <- unlist(df[,tmp[1], with = FALSE])
            vec2 <- unlist(df[,tmp[2], with = FALSE])
            
            data.table(
              variable_x = tmp[1],
              variable_y = tmp[2],
              chi2 = chisq.test(x = vec1, vec2, correct=FALSE)$p.value,
              v_cramer = cv.test(x = vec1, y = vec2)
            )
          }))
  
}

results <- v_cramer_all(cat_var = cat_var, df = cramervdata)

#Reducing number of decimals of variable v_cramer
results <- results %>% 
  mutate_if(is.numeric, round, digits = 2)

# Heatmap vizualisation with ggplot2  -------------------------------------

g <- ggplot(results, aes(variable_x, variable_y)) +
  geom_tile(aes(fill = v_cramer), colour = "black") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  theme_bw() + xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_text(angle = -90, hjust = 0)) +
  ggtitle("Cramer's V heatmap")+
  geom_text(aes(label=v_cramer))
g

#ggplotly(g)
```

# The frequentist approach

## Train/test split

We splitted the data so to leave out the last three points for prediction, because we have few points and because in this models it has no sense to predict a week, because the situation changes really fast.

```{r dataset_Giullia, include=FALSE}
covid19 <- dplyr::select(colombia_covid, -c(`Ciudad de ubicación`,`Atención`,`Tipo`))
library(fastDummies)
covid19_dummy <- dummy_cols(covid19, select_columns = c("Departamento o Distrito", "Grupo de edad", "Sexo", "País de procedencia"), remove_first_dummy = TRUE, ignore_na=TRUE, split="-", remove_selected_columns=TRUE)
group_dummy <- covid19_dummy %>%
  group_by(`Fecha de diagnóstico`) %>%
  summarise_all(funs(sum)) %>%
  dplyr::select(-c(`Fecha de diagnóstico`,`ID de caso`))
data1 <- bind_cols(cases, group_dummy)
```

## Poisson

### Poisson with `Elapsed time` as predictor

```{r pois1, results = "hold", echo=TRUE, warning=FALSE}
poisson1 <- glm(`Cumulative cases` ~ `Elapsed time`, data=data1[1:120, ], family=poisson)
plot(poisson1, which=1)
pred.pois1 <- poisson1$fitted.values
res.st1 <- (data1$`Cumulative cases`[1:120] - pred.pois1)/sqrt(pred.pois1)
#n=120, k=2, n-k=118
print(paste("Estimated overdispersion", sum(res.st1^2)/118))
poisson1.pred <- predict(poisson1, newdata = data1[120:126, ], type="response")
paste("RMSE:", sqrt(mean((poisson1.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson1$residuals^2))
#print(sprintf("MSE: %0.2f", sum(poisson1$residuals^2)/poisson1$df.residual))
#print(sprintf("MSE: %0.2f", anova(poisson1)['Residuals', 'Mean Sq']))
paste("AIC:", poisson1$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson1$null.deviance, deviance(poisson1)), 2))
```

#### Predictive accuracy of the Poisson model for `Cumulative cases`

Predicting with a $95\%$ confidence interval

```{r pre_acc_pois1, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois1 <- predict.confidence(poisson1, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_pois1 <- sum(`Cumulative cases` >= conf.df_pois1[, 2] & `Cumulative cases` <= conf.df_pois1[, 3])
paste("Frequency of coverage:", freq_coverage_pois1 <- freq_coverage_pois1/n)
detach(data1)
```

```{r precc_acc_pois1_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois1$lwr[1:120], ymax = conf.df_pois1$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois1$lwr[120:126],
              ymax = conf.df_pois1$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois1$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson1.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Using `cases_relev_dep`

```{r pois_time/dep, results = "hold", echo=TRUE, warning=FALSE}
poisson1A <- glm(`Cumulative cases/Department` ~ `Elapsed time`, data=cases_relev_dep, family=poisson)
plot(poisson1, which=1)
pred.pois1A <- poisson1A$fitted.values
res.st1A <- (data1$`Cumulative cases`[1:120] - pred.pois1A)/sqrt(pred.pois1A)
#n=120, k=2, n-k=118
print(paste("Estimated overdispersion", sum(res.st1A^2)/118))
poisson1A.pred <- predict(poisson1A, newdata = data1[120:126, ], type="response")
paste("RMSE:", sqrt(mean((poisson1A.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson1A$residuals^2))
paste("AIC:", poisson1A$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson1A$null.deviance, deviance(poisson1A)), 2))
```

We can see that the AIC is enormous.

#### Predictive accuracy of the Poisson model for `Cumulative cases`

Predicting with a $95\%$ confidence interval

```{r pre_acc_pois1A, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois1A <- predict.confidence(poisson1A, newdata = data1[1:120, ])
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_pois1A <- sum(`Cumulative cases` >= conf.df_pois1A[, 2] & `Cumulative cases` <= conf.df_pois1A[, 3])
paste("Frequency of coverage:", freq_coverage_pois1A <- freq_coverage_pois1A/n)
detach(data1)
```

```{r precc_acc_pois1A_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois1A$lwr[1:120], ymax = conf.df_pois1A$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois1A$lwr[120:126],
              ymax = conf.df_pois1A$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois1A$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson1A.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Using `New cases/day`

```{r pois1B, results = "hold", echo=TRUE, warning=FALSE}
poisson1B <- glm(`New cases/day` ~ `Elapsed time`, data=cases, family=poisson)
#print(paste("Estimated overdispersion", sum(res.st^2)/23))
plot(poisson1B, which=1)
poisson1B.pred <- predict(poisson1B, newdata = data1[120:126, ], type="response")
paste("RMSE:", sqrt(mean((poisson1B.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson1B$residuals^2))
paste("AIC:", poisson1B$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson1B$null.deviance, deviance(poisson1B)), 2))
```

#### Predictive accuracy of the Poisson model for `New cases/day`

Predicting with a $95\%$ confidence interval

```{r pre_acc_pois1B, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois1B <- predict.confidence(poisson1B, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = as.data.frame(cbind(data1$`Elapsed time`, data1$`Cumulative cases`)), interval = 'confidence')
n <- 120
freq_coverage_pois1B <- sum(`New cases/day` >= conf.df_pois1B[, 2] & `New cases/day` <= conf.df_pois1B[, 3])
paste("Frequency of coverage:", freq_coverage_pois1B <- freq_coverage_pois1B/n)
detach(data1)
```

```{r precc_acc_pois1B_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `New cases/day`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois1B$lwr[1:120], ymax = conf.df_pois1B$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois1B$lwr[120:126],
              ymax = conf.df_pois1B$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois1B$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson1B.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `New cases/day`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Daily cases") +
  scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27), labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Poisson with `Elapsed time` plus `Elapsed time`^2 as predictor

```{r pois1C, results = "hold", echo=TRUE, warning=FALSE}
poisson1C <- glm(`Cumulative cases` ~ `Elapsed time` + I(`Elapsed time`^2), data=cases[1:120, ], family=poisson)
pred.pois1C <- poisson1C$fitted.values
res.st1C <- (cases$`Cumulative cases`[1:120] - pred.pois1C)/sqrt(pred.pois1C)
#n=120, k=3, n-k=117
print(paste("Estimated overdispersion", sum(res.st1C^2)/117))
poisson1C.pred <- predict(poisson1C, newdata = cases[120:126, ], type="response")
paste("RMSE:", sqrt(mean((poisson1C.pred - cases$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson1$residuals^2))
#print(sprintf("MSE: %0.2f", sum(poisson1$residuals^2)/poisson1$df.residual))
#print(sprintf("MSE: %0.2f", anova(poisson1)['Residuals', 'Mean Sq']))
paste("AIC:", poisson1C$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson1C$null.deviance, deviance(poisson1C)), 2))
plot(poisson1C, which=1)
```

#### Predictive accuracy of the Poisson model for `Cumulative cases`

Predicting with a $95\%$ confidence interval

```{r pre_acc_pois1C, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois1C <- predict.confidence(poisson1C, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_pois1C <- sum(`Cumulative cases` >= conf.df_pois1C[, 2] & `Cumulative cases` <= conf.df_pois1C[, 3])
paste("Frequency of coverage:", freq_coverage_pois1C <- freq_coverage_pois1C/n)
detach(data1)
```

```{r precc_acc_pois1C_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois1C$lwr[1:120], ymax = conf.df_pois1C$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois1C$lwr[120:126],
              ymax = conf.df_pois1C$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois1C$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson1C.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Poisson with `Elapsed time` plus `Sexo`

```{r pois2, results = "hold", echo=TRUE, warning=FALSE}
poisson2 <- glm(`Cumulative cases` ~ `Elapsed time` + Sexo_M, data=data1[1:120, ], family=poisson)
poisson2.pred <- predict(poisson2, newdata = data1[120:126, ], type="response")
paste("RMSE:", sqrt(mean((poisson2.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson2$residuals^2))
paste("AIC:", poisson2$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson2$null.deviance, deviance(poisson2)), 2))
plot(poisson2, which=1)
```

#### Predictive accuracy of the Poisson model for `Cumulative cases`

Predicting with a $95\%$ confidence interval

```{r pre_acc_pois2, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois2 <- predict.confidence(poisson2, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_pois2 <- sum(`Cumulative cases` >= conf.df_pois2[, 2] & `Cumulative cases` <= conf.df_pois2[, 3])
paste("Frequency of coverage:", freq_coverage_pois2 <- freq_coverage_pois2/n)
detach(data1)
```

```{r precc_acc_pois2_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois2$lwr[1:120], ymax = conf.df_pois2$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois2$lwr[120:126],
              ymax = conf.df_pois2$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois2$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson2.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Poisson with `Elapsed time` plus `Group de edad`

```{r pois3, results = "hold", echo=TRUE, warning=FALSE}
poisson3 <- glm(`Cumulative cases` ~ `Elapsed time` + `Grupo de edad_19_30` + `Grupo de edad_31_45` + `Grupo de edad_46_60` + `Grupo de edad_60_75` + `Grupo de edad_76+`, data=data1[1:120, ], family=poisson)
pred.pois3 <- poisson3$fitted.values
res.st3 <- (data1$`Cumulative cases` - pred.pois3)/sqrt(pred.pois3)
#n=120, k=7, n-k=113
print(paste("Estimated overdispersion", est.overdispersion <- sum(res.st3^2)/113))
poisson3.pred <- predict(poisson3, newdata = data1[120:126, ], type="response")
paste("RMSE:", sqrt(mean((poisson3.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson3$residuals^2))
paste("AIC:", poisson3$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson3$null.deviance, deviance(poisson3)), 2))
plot(poisson3, which=1)
```

#### Predictive accuracy of the Poisson model for `Cumulative cases`

Predicting with a $95\%$ confidence interval

```{r pre_acc_pois3, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois3 <- predict.confidence(poisson3, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_pois3 <- sum(`Cumulative cases` >= conf.df_pois3[, 2] & `Cumulative cases` <= conf.df_pois3[, 3])
paste("Frequency of coverage:", freq_coverage_pois3 <- freq_coverage_pois3/n)
detach(data1)
```

```{r precc_acc_pois3_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois3$lwr[1:120], ymax = conf.df_pois3$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois3$lwr[120:126],
              ymax = conf.df_pois3$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois3$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson3.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Poisson with `Elapsed time`, `Age` and `Departments` as predictors

```{r pois4, results = "hold", echo=TRUE, warning=FALSE}
poisson4 <- glm(`Cumulative cases` ~ `Elapsed time` + `Grupo de edad_19_30` + `Grupo de edad_31_45` + `Grupo de edad_46_60` + `Grupo de edad_60_75` + `Grupo de edad_76+` + `Departamento o Distrito_Bogotá D.C.` + `Departamento o Distrito_Boyacá` + `Departamento o Distrito_Caldas` + `Departamento o Distrito_Casanare` + `Departamento o Distrito_Cauca` + `Departamento o Distrito_Cundinamarca` + `Departamento o Distrito_Meta` + `Departamento o Distrito_Quindío` + `Departamento o Distrito_Risaralda` + `Departamento o Distrito_Santander` + `Departamento o Distrito_Tolima`, data=data1[1:120, ], family=poisson)
plot(poisson4, which=1)
pred.pois4 <- poisson4$fitted.values
res.st4 <- (data1$`Cumulative cases` - pred.pois4)/sqrt(pred.pois4)
#n=120, k=17, n-k=103
print(paste("Estimated overdispersion", est.overdispersion <- sum(res.st4^2)/103))
poisson4.pred <- predict(poisson4, newdata = data1[120:126, ], type="response")
#paste("Real: ", data1$`Cumulative cases`[120:126], "Predict: ", poisson4.pred)
paste("RMSE:", sqrt(mean((poisson4.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson4$residuals^2))
paste("AIC:", poisson4$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson4$null.deviance, deviance(poisson4)), 2))
```

#### Predictive accuracy of the Poisson model for `Cumulative cases`

Predicting with a $95\%$ confidence interval

```{r pre_acc_pois4, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois4 <- predict.confidence(poisson4, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_pois4 <- sum(`Cumulative cases` >= conf.df_pois4[, 2] & `Cumulative cases` <= conf.df_pois4[, 3])
paste("Frequency of coverage:", freq_coverage_pois4 <- freq_coverage_pois4/n)
detach(data1)
```

```{r precc_acc_pois4_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois4$lwr[1:120], ymax = conf.df_pois4$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois4$lwr[120:126],
              ymax = conf.df_pois4$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois4$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson4.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Poisson with `Elapsed time`, `Age` and `Departments` as predictors for `New cases/day`

```{r pois4day, results = "hold", echo=TRUE, warning=FALSE}
poisson4bis <- glm(`New cases/day` ~ `Elapsed time` + `Grupo de edad_19_30` + `Grupo de edad_31_45` + `Grupo de edad_46_60` + `Grupo de edad_60_75` + `Grupo de edad_76+` + `Departamento o Distrito_Bogotá D.C.` + `Departamento o Distrito_Boyacá` + `Departamento o Distrito_Caldas` + `Departamento o Distrito_Casanare` + `Departamento o Distrito_Cauca` + `Departamento o Distrito_Cundinamarca` + `Departamento o Distrito_Meta` + `Departamento o Distrito_Quindío` + `Departamento o Distrito_Risaralda` + `Departamento o Distrito_Santander` + `Departamento o Distrito_Tolima`, data=data1[1:120, ], family=poisson)
plot(poisson4bis, which=1)
pred.pois4bis <- poisson4bis$fitted.values
res.st4bis <- (data1$`Cumulative cases` - pred.pois4bis)/sqrt(pred.pois4bis)
#n=120, k=18, n-k=102
print(paste("Estimated overdispersion", est.overdispersion <- sum(res.st4bis^2)/102))
poisson4bis.pred <- predict(poisson4bis, newdata = data1[120:126, ], type="response")
paste("RMSE:", sqrt(mean((poisson4bis.pred - data1$`New cases/day`[120:126])^2)))
#paste("MSE:", mean(poisson4$residuals^2))
paste("AIC:", poisson4bis$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson4bis$null.deviance, deviance(poisson4bis)), 2))
```

#### Predictive accuracy of the Poisson model for `New cases/day`

Predicting with a $95\%$ confidence interval

```{r pre_acc_pois4bis, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois4bis <- predict.confidence(poisson4bis, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = as.data.frame(cbind(data1$`Elapsed time`, data1$`Cumulative cases`)), interval = 'confidence')
n <- 120
freq_coverage_pois4bis <- sum(`New cases/day` >= conf.df_pois4bis[, 2] & `New cases/day` <= conf.df_pois4bis[, 3])
paste("Frequency of coverage:", freq_coverage_pois4bis <- freq_coverage_pois4bis/n)
detach(data1)
```

```{r precc_acc_pois_new_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `New cases/day`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois4bis$lwr[1:120], ymax = conf.df_pois4bis$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois4bis$lwr[120:126],
              ymax = conf.df_pois4bis$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois4bis$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson4bis.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `New cases/day`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Daily cases") +
  scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27), labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Poisson with `Elapsed time`, `Elapsed time`^2, `Age` and `Departments` as predictors

```{r pois5, results = "hold", echo=TRUE, warning=FALSE}
poisson5 <- glm(`Cumulative cases` ~ `Elapsed time` + I(`Elapsed time`^2) + `Grupo de edad_19_30` + `Grupo de edad_31_45` + `Grupo de edad_46_60` + `Grupo de edad_60_75` + `Grupo de edad_76+` + `Departamento o Distrito_Bogotá D.C.` + `Departamento o Distrito_Boyacá` + `Departamento o Distrito_Caldas` + `Departamento o Distrito_Casanare` + `Departamento o Distrito_Cauca` + `Departamento o Distrito_Cundinamarca` + `Departamento o Distrito_Meta` + `Departamento o Distrito_Quindío` + `Departamento o Distrito_Risaralda` + `Departamento o Distrito_Santander` + `Departamento o Distrito_Tolima`, data=data1[1:120, ], family=poisson)
plot(poisson5, which=1)
pred.pois5 <- poisson5$fitted.values
res.st5 <- (data1$`Cumulative cases` - pred.pois5)/sqrt(pred.pois5)
#n=120, k=19, n-k=101
print(paste("Estimated overdispersion", est.overdispersion <- sum(res.st5^2)/101))
poisson5.pred <- predict(poisson5, newdata = data1[120:126, ], type="response")
#paste("Real: ", data1$`Cumulative cases`[120:126], "Predict: ", poisson5.pred)
paste("RMSE:", sqrt(mean((poisson5.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson4$residuals^2))
paste("AIC:", poisson5$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson5$null.deviance, deviance(poisson5)), 2))
```

#### Predictive accuracy of the Poisson model for `Cumulative cases`

```{r pre_acc_pois5, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_pois5 <- predict.confidence(poisson5, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_pois5 <- sum(`Cumulative cases` >= conf.df_pois5[, 2] & `Cumulative cases` <= conf.df_pois5[, 3])
paste("Frequency of coverage:", freq_coverage_pois5 <- freq_coverage_pois5/n)
detach(data1)
```

```{r precc_acc_pois5_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois5$lwr[1:120], ymax = conf.df_pois5$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_pois5$lwr[120:126],
              ymax = conf.df_pois5$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_pois5$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson5.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Autocorrelation to compare Poisson models

We generated 1000 samples from each of the four Poisson models and calculated the autocorrelation and compared against the autocorrelation of our original sample.

#### Autocorrelation for the models when the response variable is `Cumulative Cases`

```{r Autocorrelation, echo=TRUE, warning=FALSE}
#Poisson1
rpois1 <- simulate(poisson1,nsim=10000)
matrix1 <- data.matrix(rpois1)

acf1 <- lapply(split(matrix1,col(matrix1)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_1 <- c()
for(i in 1:10000){ Poisson_1 <- c(Poisson_1, acf1[[c(i,1,2)]])}

#Poisson1b -> this is the model poisson1C with elapsed time squared. Let's call it Poisson1b to keep an order in the autocorrelation plot

rpois1b <- simulate(poisson1C,nsim=10000)
matrix1b <- data.matrix(rpois1b)

acf1b <- lapply(split(matrix1b,col(matrix1b)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_1b <- c()
for(i in 1:10000){ Poisson_1b <- c(Poisson_1b, acf1b[[c(i,1,2)]])}


#Poisson2
rpois2 <- simulate(poisson2,nsim=10000)
matrix2 <- data.matrix(rpois2)

acf2 <- lapply(split(matrix2,col(matrix2)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_2 <- c()
for(i in 1:10000){ Poisson_2 <- c(Poisson_2, acf2[[c(i,1,2)]])}


#Poisson3
rpois3 <- simulate(poisson3,nsim=10000)
matrix3 <- data.matrix(rpois3)

acf3 <- lapply(split(matrix3,col(matrix3)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_3 <- c()
for(i in 1:10000){ Poisson_3 <- c(Poisson_3, acf3[[c(i,1,2)]])}


#Poisson4
rpois4 <- simulate(poisson4,nsim=10000)
matrix4 <- data.matrix(rpois4)

acf4 <- lapply(split(matrix4,col(matrix4)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_4 <- c()
for(i in 1:10000){ Poisson_4 <- c(Poisson_4, acf4[[c(i,1,2)]])}

#Poisson4b -> this is the model poisson5 with elapsed time squared. Let's call it Poisson4b to keep a pattern in the autocorrelation plot

rpois4b <- simulate(poisson5,nsim=10000)
matrix4b <- data.matrix(rpois4b)

acf4b <- lapply(split(matrix4b,col(matrix4b)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_4b <- c()
for(i in 1:10000){ Poisson_4b <- c(Poisson_4b, acf4b[[c(i,1,2)]])}

#autocorrelation dataframe
autocor <- data.frame(Poisson_1,Poisson_1b,Poisson_2,Poisson_3,Poisson_4,Poisson_4b)
library(reshape2)
x1 <- melt(autocor)

#autocorrelation of original sample
tmp <- acf(data1$`Cumulative cases`,lag.max=1,plot=F)
hline1 <- as.numeric((unlist(tmp[1]))[1])

#boxplot
theme_set(theme_gray())
p<-ggplot(x1, aes(x=variable, y=value, fill=variable)) +
  geom_boxplot()+
  labs(title="Sample Autocorrelation", x="Models", y="Autocorrelation",fill='Models')+
  scale_fill_manual(values=c("#FF66FF", "#FFFF00", "#00CCFF", "green", "#6633CC", "#FF6633"))
p + geom_hline(aes(yintercept=hline1,linetype="Autocorrelation"),color="red",size=1)+
  scale_linetype_manual(name = "Original sample",values = c(1, 1))
```

#### Autocorrelation for the models when the response variable is `New cases/day`

```{r Autocorrelation2, echo=TRUE, warning=FALSE}
#PoissonA -> This is the model poisson1B. The predictor is Elapsed time.  I am changing the name to make easier to understand the presentation
rpoisA <- simulate(poisson1B,nsim=10000)
matrixA <- data.matrix(rpoisA)

acfA <- lapply(split(matrixA,col(matrixA)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_A <- c()
for(i in 1:10000){ Poisson_A <- c(Poisson_A, acfA[[c(i,1,2)]])}

#PoissonB <- This is the model poisson4bis. The predictors are elapsed time, age and departments. I am changing the name to make easier to understand the presentation.
rpoisB <- simulate(poisson4bis,nsim=10000)
matrixB <- data.matrix(rpoisB)

acfB <- lapply(split(matrixB,col(matrixB)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_B <- c()
for(i in 1:10000){ Poisson_B <- c(Poisson_B, acfB[[c(i,1,2)]])}

#autocorrelation dataframe
autocor <- data.frame(Poisson_A,Poisson_B)
library(reshape2)
x1 <- melt(autocor)

#autocorrelation of original sample
tmp2 <- acf(cases$`New cases/day`,lag.max=1,plot=F)
hline2 <- as.numeric((unlist(tmp[1]))[1])

#boxplot
theme_set(theme_gray())
p<-ggplot(x1, aes(x=variable, y=value, fill=variable)) +
  geom_boxplot()+
  labs(title="Sample Autocorrelation", x="Models", y="Autocorrelation",fill='Models')+
  scale_fill_manual(values=c("#00CCFF", "green"))
p + geom_hline(aes(yintercept=hline2,linetype="Autocorrelation"),color="red",size=1)+
  scale_linetype_manual(name = "Original sample",values = c(1, 1))
```

#### Autocorrelation for the model when the response variable is `Cumulative cases/Department`

```{r Autocorrelation3, echo=TRUE, warning=FALSE}
#Poisson Cumulative cases/Department -> This is the model poisson1A. The predictor is Elapsed time.  I am changing the name to make easier to understand the presentation
rpoisd <- simulate(poisson1A,nsim=10000)
matrixd <- data.matrix(rpoisd)

acfd <- lapply(split(matrixd,col(matrixd)), function(ts) acf(ts, lag.max=1,plot=F))

Poisson_Cumulative_Cases_Per_Department <- c()
for(i in 1:10000){ Poisson_Cumulative_Cases_Per_Department <- c(Poisson_Cumulative_Cases_Per_Department, acfd[[c(i,1,2)]])}

#autocorrelation dataframe
autocor <- data.frame(Poisson_Cumulative_Cases_Per_Department)
library(reshape2)
x1 <- melt(autocor)

#autocorrelation of original sample
tmp3 <- acf(cases_relev_dep$`Cumulative cases/Department`,lag.max=1,plot=F)
hline3 <- as.numeric((unlist(tmp[1]))[1])

#boxplot
theme_set(theme_gray())
p<-ggplot(x1, aes(x=variable, y=value, fill=variable)) +
  geom_boxplot()+
  labs(title="Sample Autocorrelation", x="Models", y="Autocorrelation",fill='Models')+
  scale_fill_manual(values=c("green"))
p + geom_hline(aes(yintercept=hline3,linetype="Autocorrelation"),color="red",size=1)+
  scale_linetype_manual(name = "Original sample",values = c(1, 1))
```

### ANOVA to compare the Poisson models

```{r Angela11, echo=TRUE, warning=FALSE}
anova(poisson1, poisson2, poisson3, poisson4, test="Chisq")
```

## Quasi-Poisson

### Quasi Poisson with `Elapsed time` as predictor

```{r quasi_pois_time, results = "hold", echo=TRUE, warning=FALSE}
poisson1quasi <- glm(`Cumulative cases` ~ `Elapsed time`, data=data1[1:120, ], family=quasipoisson)
plot(poisson1quasi, which=1)
pred.poisq <- poisson1quasi$fitted.values
res.stq <- (data1$`Cumulative cases` - pred.poisq)/sqrt(summary(poisson1quasi)$dispersion*pred.poisq)
#n=120, k= ?, n-k=?
print(paste("Estimated overdispersion", sum(res.stq^2)/23))
poisson1quasi.pred <- predict(poisson1quasi, newdata = data1[120:126, ], type = "response")
paste("RMSE:", sqrt(mean((poisson1quasi.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson1quasi$residuals^2))
paste("AIC:", poisson1quasi$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson1quasi$null.deviance, deviance(poisson1quasi)), 2))
```

#### Predictive accuracy of the Quasi-Poisson model for `Cumulative cases`

Predicting with a $95\%$ confidence interval

```{r pre_acc_qpois, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_qpois <- predict.confidence(poisson1quasi, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_qpois <- sum(`Cumulative cases` >= conf.df_qpois[, 2] & `Cumulative cases` <= conf.df_qpois[, 3])
paste("Frequency of coverage:", freq_coverage_qpois <- freq_coverage_qpois/n)
detach(data1)
```

```{r precc_acc_qpois_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_qpois$lwr[1:120], ymax = conf.df_qpois$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_qpois$lwr[120:126],
              ymax = conf.df_qpois$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_qpois$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson1quasi.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Quasi Poisson with `Elapsed time` and `Age` as predictor

```{r quasi_pois, results = "hold", echo=TRUE, warning=FALSE}
poisson2quasi <- glm(`Cumulative cases` ~ `Elapsed time` + `Grupo de edad_19_30` + `Grupo de edad_31_45` + `Grupo de edad_46_60` + `Grupo de edad_60_75` + `Grupo de edad_76+`, data=data1[1:120, ], family=quasipoisson)
plot(poisson1quasi, which=1)
pred.poisq2 <- poisson2quasi$fitted.values
res.stq2 <- (data1$`Cumulative cases` - pred.poisq2)/sqrt(summary(poisson2quasi)$dispersion*pred.poisq2)
#n=120, k= ?, n-k=?
print(paste("Estimated overdispersion", sum(res.stq2^2)/18))
poisson2quasi.pred <- predict(poisson2quasi, newdata = data1[120:126, ], type = "response")
paste("RMSE:", sqrt(mean((poisson2quasi.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(poisson2quasi$residuals^2))
paste("AIC:", poisson2quasi$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(poisson2quasi$null.deviance, deviance(poisson2quasi)), 2))
```

#### Predictive accuracy of the Quasi-Poisson model for `Cumulative cases`

Predicting with a $95\%$ confidence interval

```{r pre_acc_qpois2, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_qpois2 <- predict.confidence(poisson2quasi, newdata = data1)
#conf.df_pois <- predict.glm(poisson4, newdata = data1, interval = "confidence", type="response")
n <- 120
freq_coverage_qpois2 <- sum(`Cumulative cases` >= conf.df_qpois2[, 2] & `Cumulative cases` <= conf.df_qpois2[, 3])
paste("Frequency of coverage:", freq_coverage_qpois2 <- freq_coverage_qpois2/n)
detach(data1)
```

```{r precc_acc_qpois2_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_qpois2$lwr[1:120], ymax = conf.df_qpois2$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_qpois2$lwr[120:126],
              ymax = conf.df_qpois2$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_qpois2$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = poisson2quasi.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27),
  #              labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

## Negative Binomial

### Negative Binomial with `Elapsed time` as predictor

```{r nb1, results = "hold", echo=TRUE, warning=FALSE}
nb1 <- glm.nb(`Cumulative cases` ~ `Elapsed time`, data=data1[1:120, ])
plot(nb1, which=1)
#n=120, k=2, n-k=118
stdres <- rstandard(nb1)
print(paste("Estimated overdispersion", sum(stdres^2)/118))
nb1.pred <- predict(nb1, newdata = data1[120:126, ], type = "response")
paste("RMSE:", sqrt(mean((nb1.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(nb1$residuals^2))
paste("AIC:", nb1$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(nb1$null.deviance, deviance(nb1)), 2))
```

#### Predictive accuracy of the Negative Binomial model

Predicting with a $95\%$ confidence interval

```{r pre_acc_nb1, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_nb1 <- predict.confidence(nb1, newdata = data1)
#conf.df_nb1 <- predict.glm(nb5, newdata = as.data.frame(cbind(data1$`Elapsed time`, data1$`Cumulative cases`)), interval = 'confidence')
n <- 120
freq_coverage_nb1 <- sum(`Cumulative cases` >= conf.df_nb1[, 2] & `Cumulative cases` <= conf.df_nb1[, 3])
paste("Frequency of coverage:", freq_coverage_nb1 <- freq_coverage_nb1/n)
detach(data1)
```

```{r precc_acc_nb1_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb1$lwr[1:120], ymax = conf.df_nb1$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb1$lwr[120:126], ymax = conf.df_nb1$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_nb1$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = nb1.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27), labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap(~"Department", scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Negative Binomial with `Elapsed time` plus `Age` as predictors

```{r nb2, results = "hold", echo=TRUE, warning=FALSE}
nb2 <- glm.nb(`Cumulative cases` ~ `Elapsed time` + `Grupo de edad_19_30` + `Grupo de edad_31_45` + `Grupo de edad_46_60` + `Grupo de edad_60_75` + `Grupo de edad_76+`, data=data1[1:120, ])
plot(nb2, which=1)
nb2.pred <- predict(nb2, newdata = data1[120:126, ], type = "response")
paste("RMSE:", sqrt(mean((nb2.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(nb2$residuals^2))
paste("AIC:", nb2$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(nb2$null.deviance, deviance(nb2)), 2))
```

#### Predictive accuracy of the Negative Binomial model

Predicting with a $95\%$ confidence interval

```{r pre_acc_nb2, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_nb2 <- predict.confidence(nb2, newdata = data1)
#conf.df_nb <- predict.glm(nb5, newdata = as.data.frame(cbind(data1$`Elapsed time`, data1$`Cumulative cases`)), interval = 'confidence')
n <- 120
freq_coverage_nb2 <- sum(`Cumulative cases` >= conf.df_nb2[, 2] & `Cumulative cases` <= conf.df_nb2[, 3])
paste("Frequency of coverage:", freq_coverage_nb2 <- freq_coverage_nb2/n)
detach(data1)
```

```{r precc_acc_nb2_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb2$lwr[1:120], ymax = conf.df_nb2$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb2$lwr[120:126], ymax = conf.df_nb2$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_nb2$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = nb2.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27), labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap(~"Department", scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Negative Binomial with `Elapsed time` plus `Department` as predictors

```{r nb3, results = "hold", echo=TRUE, warning=FALSE}
nb3 <- glm.nb(`Cumulative cases` ~ `Elapsed time` + `Departamento o Distrito_Bogotá D.C.` + `Departamento o Distrito_Boyacá`+`Departamento o Distrito_Caldas`+`Departamento o Distrito_Casanare`+`Departamento o Distrito_Cauca`+`Departamento o Distrito_Cundinamarca`+`Departamento o Distrito_Meta`+`Departamento o Distrito_Quindío`+`Departamento o Distrito_Risaralda`+`Departamento o Distrito_Santander`+`Departamento o Distrito_Tolima`, data=data1[1:120, ])
plot(nb3, which=1)
nb3.pred <- predict(nb3, newdata = data1[120:126, ], type = "response")
paste("RMSE:", sqrt(mean((nb3.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(nb3$residuals^2))
paste("AIC:", nb3$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(nb3$null.deviance, deviance(nb3)), 2))
```

#### Predictive accuracy of the Negative Binomial model

Predicting with a $95\%$ confidence interval

```{r pre_acc_nb3, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_nb3 <- predict.confidence(nb3, newdata = data1)
#conf.df_nb <- predict.glm(nb5, newdata = as.data.frame(cbind(data1$`Elapsed time`, data1$`Cumulative cases`)), interval = 'confidence')
n <- 120
freq_coverage_nb3 <- sum(`Cumulative cases` >= conf.df_nb3[, 2] & `Cumulative cases` <= conf.df_nb3[, 3])
paste("Frequency of coverage:", freq_coverage_nb3 <- freq_coverage_nb3/n)
detach(data1)
```

```{r precc_acc_nb3_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb3$lwr[1:120], ymax = conf.df_nb3$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb3$lwr[120:126], ymax = conf.df_nb3$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_nb3$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = nb3.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27), labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap(~"Department", scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Negative Binomial with `Elapsed time` plus `Continent of origin` as predictors

```{r nb4, results = "hold", echo=TRUE, warning=FALSE}
# nb4 <- glm.nb(`Cumulative cases` ~ `Elapsed time` + `Continente de procedencia_Asia`+`Continente de procedencia_Centroamérica`+`Continente de procedencia_Colombia`+`Continente de procedencia_Europa`+`Continente de procedencia_Norteamérica`+`Continente de procedencia_Sudamerica`, data=data1[1:22, ])
# plot(nb4, which=1)
# nb4.pred <- predict(nb4, newdata = data1[23:25, ], type = "response")
# paste("RMSE:", sqrt(mean((nb4.pred - data1$`Cumulative cases`[23:25])^2)))
# #paste("MSE:", mean(nb4$residuals^2))
# paste("AIC:", nb4$aic)
# paste(c("Null deviance: ", "Residual deviance:"),
#        round(c(nb4$null.deviance, deviance(nb4)), 2))
```

### Negative Binomial with `Elapsed time`, `Age` and `Departments` as pedictors

```{r nb5, results = "hold", echo=TRUE, warning=FALSE}
nb4 <- glm.nb(`Cumulative cases` ~ `Elapsed time` + `Grupo de edad_19_30` + `Grupo de edad_31_45` + `Grupo de edad_46_60` + `Grupo de edad_60_75` + `Grupo de edad_76+` + `Departamento o Distrito_Bogotá D.C.`+`Departamento o Distrito_Boyacá`+`Departamento o Distrito_Caldas`+`Departamento o Distrito_Casanare`+`Departamento o Distrito_Cauca`+`Departamento o Distrito_Cundinamarca`+`Departamento o Distrito_Meta`+`Departamento o Distrito_Quindío`+`Departamento o Distrito_Risaralda`+`Departamento o Distrito_Santander`+`Departamento o Distrito_Tolima`, data=data1[1:120, ])
plot(nb4, which=1)
# Calculating overdispersion n=120 k=19 n-k=101
stdres <- rstandard(nb4)
print(paste("Estimated overdispersion", sum(stdres^2)/101))
nb4.pred <- predict(nb4, newdata = data1[120:126, ], type = "response")
paste("RMSE:", sqrt(mean((nb4.pred - data1$`Cumulative cases`[120:126])^2)))
#paste("MSE:", mean(nb5$residuals^2))
paste("AIC:", nb4$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(nb4$null.deviance, deviance(nb4)), 2))
```

#### Predictive accuracy of the Negative Binomial model

Predicting with a $95\%$ confidence interval

```{r pre_acc_nb4, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_nb4 <- predict.confidence(nb4, newdata = data1[1:120, ])
#conf.df_nb <- predict.glm(nb5, newdata = as.data.frame(cbind(data1$`Elapsed time`, data1$`Cumulative cases`)), interval = 'confidence')
n <- 120
freq_coverage_nb4 <- sum(`Cumulative cases` >= conf.df_nb4[, 2] & `Cumulative cases` <= conf.df_nb4[, 3])
paste("Frequency of coverage:", freq_coverage_nb4 <- freq_coverage_nb4/n)
detach(data1)
```

```{r precc_acc_nb4_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `Cumulative cases`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb4$lwr[1:120], ymax = conf.df_nb4$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb4$lwr[120:126], ymax = conf.df_nb4$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_nb4$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = nb4.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `Cumulative cases`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Total cases") +
  #scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27), labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap(~"Department", scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Negative Binomial with `Elapsed time`, `Age` and `Departments` as pedictors

```{r nb5bis, results = "hold", echo=TRUE, warning=FALSE}
nb5bis <- glm.nb(`New cases/day` ~ `Elapsed time` + `Grupo de edad_19_30` + `Grupo de edad_31_45` + `Grupo de edad_46_60` + `Grupo de edad_60_75` + `Grupo de edad_76+` + `Departamento o Distrito_Bogotá D.C.`+`Departamento o Distrito_Boyacá`+`Departamento o Distrito_Caldas`+`Departamento o Distrito_Casanare`+`Departamento o Distrito_Cauca`+`Departamento o Distrito_Cundinamarca`+`Departamento o Distrito_Meta`+`Departamento o Distrito_Quindío`+`Departamento o Distrito_Risaralda`+`Departamento o Distrito_Santander`+`Departamento o Distrito_Tolima`, data=data1[1:120, ])
plot(nb5bis, which=1)
# Calculating overdispersion n=120 k=19 n-k=101
stdres2 <- rstandard(nb5bis)
print(paste("Estimated overdispersion", sum(stdres2^2)/101))
nb5bis.pred <- predict(nb5bis, newdata = data1[120:126, ], type = "response")
paste("RMSE:", sqrt(mean((nb5bis.pred - data1$`New cases/day`[120:126])^2)))
#paste("MSE:", mean(nb5bis$residuals^2))
paste("AIC:", nb5bis$aic)
paste(c("Null deviance: ", "Residual deviance:"),
       round(c(nb5bis$null.deviance, deviance(nb5bis)), 2))
```

#### Predictive accuracy of the NB model for `New cases/day`

Predicting with a $95\%$ confidence interval

```{r pre_acc_nb5bis, echo=FALSE, warning=FALSE}
attach(data1)
conf.df_nb5bis <- predict.confidence(nb5bis, newdata = data1[1:120, ])
#conf.df_nb2 <- predict.glm(nb5, newdata = data1[1:120, ], interval = 'confidence')
n <- 120
freq_coverage_nb5bis <- sum(`New cases/day` >= conf.df_nb5bis[, 2] & `New cases/day` <= conf.df_nb5bis[, 3])
paste("Frequency of coverage:", freq_coverage_nb5bis <- freq_coverage_nb5bis/n)
detach(data1)
```

```{r precc_acc_nb5bis_plot, echo=FALSE, warning=FALSE}
ggplot(data1, aes(`Elapsed time`, `New cases/day`)) +
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb5bis$lwr[1:120], ymax = conf.df_nb5bis$upr[1:120]),
              data = data1[1:120, ],
              fill = color_scheme_get("blue")[[2]]) + 
  geom_ribbon(aes(x = `Elapsed time`, ymin = conf.df_nb5bis$lwr[120:126], ymax = conf.df_nb5bis$upr[120:126]),
              data = data1[120:126, ],
              fill = color_scheme_get("red")[[2]]) +
  geom_line(aes(x = `Elapsed time`, y = conf.df_nb5bis$fit[1:120]),
              data = data1[1:120, ],
              color = color_scheme_get("blue")[[4]], 
              size = 1.1) +
  geom_line(aes(x= `Elapsed time`, y = nb5bis.pred),
              data = data1[120:126, ],
              color = color_scheme_get("red")[[4]],
              size = 1.1) +
  geom_point(aes(x = `Elapsed time`, y = `New cases/day`)) +
  expand_limits(x = 28) +
  ggtitle("Central Colombia") + xlab("Days") + ylab("Daily cases") +
  scale_x_discrete(limit = c(0, 7, 12, 17, 22, 27), labels = c("3-06", "3-13", "3-18", "3-23", "3-28", "4-02")) +
  # facet_wrap('reg', scales ='free') +
  theme(strip.text.x = element_text(size = 12, colour = "black"),
        axis.text.x = element_text(face = "bold",
        color = "#993333", angle = 45, size = 9),
        plot.title = element_text(size = 22),
        axis.title.x = element_text(size = 18), 
        axis.title.y = element_text(size = 18))
```

### Autocorrelation to compare Negative Binomial models

We generated 1000 samples from each of the four Negative Binomial models and calculated the autocorrelation and compared against the autocorrelation of our original sample.

#### Autocorrelation for the models when the response variable is `Cumulative Cases`

```{r Autocorrelation4, echo=TRUE, warning=FALSE}
#nb1
rnb1 <- simulate(nb1,nsim=10000)
mat1 <- data.matrix(rnb1)

acfnb1 <- lapply(split(mat1,col(mat1)), function(ts) acf(ts, lag.max=1,plot=F))

Neg.Bin_1 <- c()
for(i in 1:10000){ Neg.Bin_1 <- c(Neg.Bin_1, acfnb1[[c(i,1,2)]])}

#nb2
rnb2 <- simulate(nb2,nsim=10000)
mat2 <- data.matrix(rnb2)

acfnb2 <- lapply(split(mat2,col(mat2)), function(ts) acf(ts, lag.max=1,plot=F))

Neg.Bin_2 <- c()
for(i in 1:10000){ Neg.Bin_2 <- c(Neg.Bin_2, acfnb2[[c(i,1,2)]])}


#nb3
rnb3 <- simulate(nb3,nsim=10000)
mat3 <- data.matrix(rnb3)

acfnb3 <- lapply(split(mat3,col(mat3)), function(ts) acf(ts, lag.max=1,plot=F))

Neg.Bin_3 <- c()
for(i in 1:10000){ Neg.Bin_3 <- c(Neg.Bin_3, acfnb3[[c(i,1,2)]])}


#nb4
rnb4 <- simulate(nb4,nsim=10000)
mat4 <- data.matrix(rnb4)

acfnb4 <- lapply(split(mat4,col(mat4)), function(ts) acf(ts, lag.max=1,plot=F))

Neg.Bin_4 <- c()
for(i in 1:10000){ Neg.Bin_4 <- c(Neg.Bin_4, acfnb4[[c(i,1,2)]])}

#autocorrelation dataframe
autocor <- data.frame(Neg.Bin_1,Neg.Bin_2,Neg.Bin_3,Neg.Bin_4)
x1 <- melt(autocor)

#autocorrelation of original sample
#tmp <- acf(data1$`Cumulative cases`,lag.max=1,plot=F)
#hline1 <- as.numeric((unlist(tmp[1]))[1])

#boxplot
theme_set(theme_gray())
q<-ggplot(x1, aes(x=variable, y=value, fill=variable)) +
  geom_boxplot()+
  labs(title="Sample Autocorrelation", x="Models", y="Autocorrelation",fill='Models')+
  scale_fill_manual(values=c("#FFFF00", "#FF66FF", "#00CCFF", "green"))
q + geom_hline(aes(yintercept=hline1,linetype="Autocorrelation"),color="red",size=1)+
  scale_linetype_manual(name = "Original sample",values = c(1, 1))
```

#### Autocorrelation for the model when the response variable is `New cases/day`

```{r Autocorrelation5, echo=TRUE, warning=FALSE}
#Neg.Bin_A -> This is the model nb5bis.  I am changing the name to make easier to understand the presentation
rnbA <- simulate(nb5bis,nsim=10000)
matrixnbA <- data.matrix(rnbA)

acfnbA <- lapply(split(matrixnbA,col(matrixnbA)), function(ts) acf(ts, lag.max=1,plot=F))

Neg.Bin_A <- c()
for(i in 1:10000){ Neg.Bin_A <- c(Neg.Bin_A, acfnbA[[c(i,1,2)]])}

#autocorrelation dataframe
autocor <- data.frame(Neg.Bin_A)
library(reshape2)
x1 <- melt(autocor)

#autocorrelation of original sample
tmp2 <- acf(cases$`New cases/day`,lag.max=1,plot=F)
hline2 <- as.numeric((unlist(tmp[1]))[1])

#boxplot
theme_set(theme_gray())
p<-ggplot(x1, aes(x=variable, y=value, fill=variable)) +
  geom_boxplot()+
  labs(title="Sample Autocorrelation", x="Models", y="Autocorrelation",fill='Models')+
  scale_fill_manual(values=c("green"))
p + geom_hline(aes(yintercept=hline2,linetype="Autocorrelation"),color="red",size=1)+
  scale_linetype_manual(name = "Original sample",values = c(1, 1))
```

### Applying ANOVA to compare the negative binomial models

```{r anova_nb, echo=TRUE, warning=FALSE}
#Applying ANOVA to compare the negative binomial models
anova(nb1, nb2, nb3, nb4)
```


# The Bayesian approach

## Poisson regression for response variable `Cumulative cases/Department`
As a first attempt, we fit a simple Poisson regression:

$$
ln(\lambda_i) = \alpha + \beta\cdot elapsed\_time_i \\
y_i \sim \mathcal{Poisson}(\lambda_i) \\
\alpha \sim \mathcal{N}(0,1) \\
\beta \sim \mathcal{N}(0.25,1)
$$

with $i = 1,\dots,134$, being $134$ the number of rows of our dataset, and $y_i$ represents the number of cases.

For what concerns the `stan` program, we used the function `poisson_log_rng` to describe the distribution of $y_i$, namely the number of cases each day and the function `poisson_log_lpmf` to specify the likelihood.

```{r stan_poisson_regression, warning=FALSE, include=FALSE, eval=FALSE}
model.data <- list(
  N = nrow(cases_dep),
  cases = cases_dep$`Cumulative cases/Department`,
  time = cases_dep$`Elapsed time`
)

fit1 <- stan("stan/poisson_regression.stan", data=model.data, chains = 4, iter = 2000)
```

## Posterior predictive check - Poisson `Cumulative cases/Department`

```{r poisson_posterior, echo=TRUE, warning=FALSE, eval=FALSE}
y_rep <- as.matrix(fit1, pars="y_rep")
ppc_dens_overlay(y = model.data$cases, y_rep[1:400,]) + 
  coord_cartesian(xlim = c(-1, 7000))
```

<img src="stan_figs/poisson_cumulative.png" alt="poisson_cumulative" style="zoom:100%;" class="center"/>

The fit is not satisfactory, it is probably due to overdispersion, we can check the residuals to confirm this hypothesis.

```{r poisson_posterior_ecdf, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_ecdf_overlay(model.data$cases, y_rep[1:200,])
```

<img src="stan_figs/poisson_cumulative_ecdf.png" alt="poisson_cumulative_ecdf" style="zoom:100%;" class="center"/>

## Residual check - Poisson `Cumulative cases/Department`

```{r first_residual, echo=TRUE, warning=FALSE, eval=FALSE}
#in this way we check the standardized residuals
mean_y_rep <- colMeans(y_rep)
std_residual <- (model.data$cases - mean_y_rep) / sqrt(mean_y_rep)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

<img src="stan_figs/poisson_cumulative_res.png" alt="poisson_cumulative_res" style="zoom:100%;" class="center"/>

The variance of the residuals increases as the predicted value increase. The standardized residuals should have mean 0 and standard deviation 1 (hence the lines at $+2$ and $-2$ indicates approximate $95\%$ error bounds). 

The plot of the standardized residuals indicates a large amount of overdispersion. 

## Intervals - Poisson `Cumulative cases/Department`

```{r Poisson_intervals, echo=FALSE, warning=FALSE, eval=FALSE}
ppc_intervals(
  y = cases_dep$`Cumulative cases/Department`, 
  yrep = y_rep,
  x = cases_dep$`Elapsed time`
) + 
  labs(x = "Days", y = "Cases")
```

<img src="stan_figs/poisson_cumulative_intervals.png" alt="poisson_cumulative_intervals" style="zoom:100%;" class="center"/>

## Accuracy - Poisson `Cumulative cases/Department`

```{r Poisson_accuracy, echo=FALSE, warning=FALSE, eval=FALSE}
ppc_stat_grouped(
  y = model.data$cases,
  yrep = y_rep,
  group = cases_dep$Department,
  stat = "median",
  binwidth = 0.2
)
```

<img src="stan_figs/poisson_cumulative_acc.png" alt="poisson_cumulative_acc" style="zoom:100%;" class="center"/>

```{r Poisson_looic, echo=FALSE, warning=FALSE, eval=FALSE}
loo.model.Poisson <- loo(fit1)$estimates
```

## Poisson model for `new cases/day`

Same model, but now $y_i$ represents `New cases/day`.

```{r stan_poisson_new_cases, warning=FALSE, include=FALSE, eval=FALSE}
model.data.cases <- list(
  N = nrow(cases_dep),
  cases = cases_dep$`New cases/day`,
  time = cases_dep$`Elapsed time`
)

fit1.1 <- stan("stan/poisson_regression.stan", data=model.data.cases, chains = 4, iter = 2000)
```

## Posterioir predictive check - Poisson `new cases/day`

```{r poisson_posterior_cases, echo=TRUE, warning=FALSE, eval=FALSE}
y_rep <- as.matrix(fit1.1, pars="y_rep")
ppc_dens_overlay(y = model.data.cases$cases, y_rep[1:200,]) + 
  coord_cartesian(xlim = c(-1, 1500))
```

<img src="stan_figs/poisson_cases.png" alt="poisson_cases" style="zoom:100%;" class="center"/>

```{r poisson_posterior_cases_ecdf, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_ecdf_overlay(model.data.cases$cases, y_rep[1:200,])
```

<img src="stan_figs/poisson_cases_ecdf.png" alt="poisson_cases_ecdf" style="zoom:100%;" class="center"/>

## Residual check - Poisson `new cases/day`

```{r first_residual_cases, echo=TRUE, warning=FALSE, eval=FALSE}
#in this way we check the standardized residuals
mean_y_rep <- colMeans(y_rep)
std_residual <- (model.data.cases$cases - mean_y_rep) / sqrt(mean_y_rep)
qplot(mean_y_rep, std_residual, ylim=c(-5, 10)) + hline_at(2) + hline_at(-2)
```

<img src="stan_figs/poisson_cases_res.png" alt="poisson_cases_res" style="zoom:100%;" class="center"/>

## Intervals - Poisson `new cases/day`

```{r Poisson_intervals_cases, echo=FALSE, warning=FALSE, eval=FALSE}
ppc_intervals(
  y = cases_dep$`New cases/day`, 
  yrep = y_rep,
  x = cases_dep$`Elapsed time`
) + 
  labs(x = "Days", y = "Cases")
```

<img src="stan_figs/poisson_cases_intervals.png" alt="poisson_cases_intervals" style="zoom:100%;" class="center"/>

## Accuracy - Poisson `new cases/day`

```{r Poisson_accuracy_cases, echo=FALSE, warning=FALSE, eval=FALSE}
ppc_stat_grouped(
  y = model.data.cases$cases,
  yrep = y_rep,
  group = cases_dep$Department,
  stat = "median",
  binwidth = 0.2
)
```

<img src="stan_figs/poisson_cases_acc.png" alt="poisson_cases_acc" style="zoom:100%;" class="center"/>

```{r looic_poisson_cases}
loo.model.Poisson.cases <- loo(fit1.1)$estimates
```

## Negative Binomial model - `Cumulative cases /Department`

We try to improve the previous model using the Negative Binomial model:

$$
ln(\lambda_i) = \alpha + \beta\cdot elapsed\_time_i \\
y_i \sim \mathcal{Negative Binomial}(\lambda_i, \phi)  \\
\alpha \sim \mathcal{N}(0,1) \\
\beta \sim \mathcal{N}(0.25,1)
$$

Where the parameter $\phi$ is called *precision* and it is such that:

$$
E[y_i] = \lambda_i \\  Var[y_i] = \lambda_i + \frac{\lambda_i^2}{\phi}
$$

again $i=1,\dots,134$. As $\phi \rightarrow \infty$ the negative binomial approaches the Poisson distribution.

The `stan` function that we use here are `neg_binomial_2_log_rng` to specify the distribution of $y_i$ and the function `neg_binomial_2_log_lpmf` for the likelihood.

```{r NB1, echo=FALSE, warning=FALSE, eval=FALSE}
#compile
model.NB <- stan_model("stan/negative_binomial.stan")
#fit
fit2 <- sampling(model.NB, data=model.data)
```

## Posterior predictive check - NB `Cumulative cases /Department`

```{r NB_posterior, echo=TRUE, warning=FALSE, eval=FALSE}
samples_NB <- rstan::extract(fit2)
y_rep <- samples_NB$y_rep
ppc_dens_overlay(y = model.data$cases, y_rep[1:200,]) + 
  coord_cartesian(xlim = c(-1, 6000))
```

<img src="stan_figs/NB_cumualtive.png" alt="NB_cumulative" style="zoom:100%;" class="center"/>

```{r NB_posterior, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_ecdf_overlay(model.data$cases, y_rep)
```

<img src="stan_figs/NB_cumualtive_ecdf.png" alt="NB_cumulative_ecdf" style="zoom:100%;" class="center"/>

## Residual check - NB `Cumulative cases /Department`

```{r looic_NB, eval=FALSE, warning=FALSE, include=FALSE}
loo.model.NB <- loo(fit2)$estimates
```

```{r residuals_NB, echo=TRUE, warning=FALSE, eval=FALSE}
mean_inv_phi <- mean(samples_NB$inv_phi)
mean_y_rep <- colMeans(y_rep)
std_residual <- (model.data$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

<img src="stan_figs/NB_cumualtive_res.png" alt="NB_cumulative_res" style="zoom:100%;" class="center"/>

The situation is better now, but still we have too many residuals outside the $95\%$ interval.

## Intervals - NB `Cumulative cases /Department`

```{r intervals_NB, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_intervals(
  y = cases_dep$`Cumulative cases/Department`, 
  yrep = y_rep,
  x = cases_dep$`Elapsed time`
) + 
  labs(x = "Days", y = "Cases")
```

<img src="stan_figs/NB_cumualtive_intervals.png" alt="NB_cumulative_intervals" style="zoom:100%;" class="center"/>

## Accuracy across departments - NB `Cumulative cases /Department`

```{r NB_deps, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_stat_grouped(
  y = model.data$cases,
  yrep = y_rep,
  group = cases_dep$Department,
  stat = "median",
  binwidth = 0.2
)
```

<img src="stan_figs/NB_cumulative_acc" alt="NB_cumulative_acc" style="zoom:100%;" class="center"/>

We should take into account the differences across departments. 

## Negative binomial for `New cases/day`

```{r NB1_cases, echo=FALSE, warning=FALSE, eval=FALSE}
#fit
fit2.1 <- sampling(model.NB, data=model.data.cases)
```

## Posterior predictive check - NB `New cases/day`

```{r NB_posterior_cases, echo=TRUE, warning=FALSE, eval=FALSE}
samples_NB <- rstan::extract(fit2.1)
y_rep <- samples_NB$y_rep
ppc_dens_overlay(y = model.data.cases$cases, y_rep[1:200,]) + 
  coord_cartesian(xlim = c(-1, 1000))
```

<img src="stan_figs/NB_cases.png" alt="NB_cases" style="zoom:100%;" class="center"/>

```{r NB_posterior_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_ecdf_overlay(model.data.cases$cases, y_rep)
```

<img src="stan_figs/NB_cases_ecdf.png" alt="NB_cases_ecdf" style="zoom:100%;" class="center"/>

## Residual check - NB `New cases/day`

```{r looic_NB_cases, eval=FALSE, warning=FALSE, include=FALSE}
loo.model.NB.cases <- loo(fit2.1)$estimates
```

```{r residuals_NB_cases, echo=TRUE, warning=FALSE, eval=FALSE}
mean_inv_phi <- mean(samples_NB$inv_phi)
mean_y_rep <- colMeans(y_rep)
std_residual <- (model.data.cases$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

<img src="stan_figs/NB_cases_res.png" alt="NB_cases_res" style="zoom:100%;" class="center"/>

The situation is better now, but still we have too many residuals outside the $95\%$ interval.

## Intervals - NB ``New cases/day`

```{r intervals_NB_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_intervals(
  y = cases_dep$`New cases/day`, 
  yrep = y_rep,
  x = cases_dep$`Elapsed time`
) + 
  labs(x = "Days", y = "Cases")
```

<img src="stan_figs/NB_cases_intervals.png" alt="NB_cases_intervals" style="zoom:100%;" class="center"/>

## Accuracy across departments - NB `New cases/day`

```{r NB_deps_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_stat_grouped(
  y = model.data.cases$cases,
  yrep = y_rep,
  group = cases_dep$Department,
  stat = "median",
  binwidth = 0.2
)
```

<img src="stan_figs/NB_cases_acc" alt="NB_cases_acc" style="zoom:100%;" class="center"/>

## Multilevel Negative Binomial regression for `Cumulative/Department`

We try to fit the following model, which also includes `Age` as covariat:

$$
ln(\lambda_i) = \alpha + \beta_{time}\cdot elapsed\_time_i + \beta_{age}\cdot age \\
y_i \sim \mathcal{Negative Binomial}(\lambda_i, \phi) \\
\alpha \sim \mathcal{N}(0,1) \\
\beta_{time} \sim \mathcal{N}(0.5,1) \\
\beta_{age} \sim \mathcal{N}(0,1)
$$

```{r NB2_fit, echo=FALSE, warning=FALSE, eval=FALSE}
#compile
model2.NB<-stan_model("stan/NB_model2.stan")
#arrange data
model.data2<-list(
  N = nrow(cases_dep),
  cases = cases_dep$`Cumulative cases/Department`,
  time = cases_dep$`Elapsed time`,
  age = cases_dep$`Mean age`
)
#fit
fit3<-sampling(model2.NB, model.data2)
```

## Posterior predictive check - multi NB `Cumulative/Department`

```{r NB2_posterior_check, echo=TRUE, warning=FALSE, eval=FALSE}
samples_NB2 <- rstan::extract(fit3)
y_rep <- samples_NB2$y_rep
ppc_dens_overlay(y = model.data2$cases, y_rep[1:200,]) + 
  coord_cartesian(xlim = c(-1, 6000))
```

<img src="stan_figs/NB2_cumulative.png" alt="NB2_cumulative" style="zoom:100%;" class="center"/>

```{r NB2_cum_ecdf, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_ecdf_overlay(cases_dep$`Cumulative cases/Department`, y_rep)
```

<img src="stan_figs/NB2_cumulative_ecdf.png" alt="NB2_cumulative_ecdf" style="zoom:100%;" class="center"/>

```{r looic_NB2, echo=FALSE, warning=FALSE, eval=FALSE}
loo.model.NB2 <- loo(fit3)$estimates
```

## Residual check - multi NB `Cumulative/Department`

```{r residuals_NB2, echo=TRUE, warning=FALSE, eval=FALSE}
mean_inv_phi <- mean(samples_NB2$inv_phi)
mean_y_rep <- colMeans(y_rep)
std_residual <- (model.data2$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

<img src="stan_figs/NB2_cumulative_res.png" alt="NB2_cumulative_res" style="zoom:100%;" class="center"/>

## Intervals - - multi NB `Cumulative/Department`

```{r intervals_NB2, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_intervals(
  y = cases_dep$`Cumulative cases/Department`, 
  yrep = y_rep,
  x = cases_dep$`Elapsed time`
) + 
  labs(x = "Days", y = "Cases")
```

<img src="stan_figs/NB2_cumulative_intervals.png" alt="NB2_cumulative_intervals" style="zoom:100%;" class="center"/>

## Accuracy across departments - multi NB `Cumulative/Department`

```{r deps_NB2, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_stat_grouped(
  y = model.data2$cases,
  yrep = y_rep,
  group = cases_dep$Department,
  stat = "median",
  binwidth = 0.2
)
```

<img src="stan_figs/NB2_cumulative_acc.png" alt="NB2_cumulative_acc" style="zoom:100%;" class="center"/>

## Multilevel Negative Binomial Regression for `New cases/day`

```{r NB2_fit_cases, echo=FALSE, warning=FALSE, eval=FALSE}
#arrange data
model.data2.cases<-list(
  N = nrow(cases_dep),
  cases = cases_dep$`New cases/day`,
  time = cases_dep$`Elapsed time`,
  age = cases_dep$`Mean age`
)
#fit
fit3.1<-sampling(model2.NB, model.data2.cases)
```

## Posterior predictive check - multi NB `New cases/day`

```{r NB2_posterior_check_cases, echo=TRUE, warning=FALSE, eval=FALSE}
samples_NB2 <- rstan::extract(fit3.1)
y_rep <- samples_NB2$y_rep
ppc_dens_overlay(y = model.data2.cases$cases, y_rep[1:200,]) + 
  coord_cartesian(xlim = c(-1, 750))
```

<img src="stan_figs/NB2_cases.png" alt="NB2_cases" style="zoom:100%;" class="center"/>

```{r NB2_cum_ecdf_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_ecdf_overlay(cases_dep$`New cases/day`, y_rep)
```

<img src="stan_figs/NB2_cases_ecdf.png" alt="NB2_cases_ecdf" style="zoom:100%;" class="center"/>

```{r looic_NB2_cases, echo=FALSE, warning=FALSE, eval=FALSE}
loo.model.NB2.cases <- loo(fit3.1)$estimates
```

## Residual check - multi NB `New cases/day`

```{r residuals_NB2_cases, echo=TRUE, warning=FALSE, eval=FALSE}
mean_inv_phi <- mean(samples_NB2$inv_phi)
mean_y_rep <- colMeans(y_rep)
std_residual <- (model.data2.cases$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

<img src="stan_figs/NB2_cases_res.png" alt="NB2_cases_res" style="zoom:100%;" class="center"/>

## Intervals - multi NB `New cases/day`

```{r intervals_NB2_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_intervals(
  y = cases_dep$`New cases/day`, 
  yrep = y_rep,
  x = cases_dep$`Elapsed time`
) + 
  labs(x = "Days", y = "Cases")
```

<img src="stan_figs/NB2_cases_intervals.png" alt="NB2_cases_intervals" style="zoom:100%;" class="center"/>

## Accuracy across departments - multi NB `New cases/day`

```{r deps_NB2_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_stat_grouped(
  y = model.data2.cases$cases,
  yrep = y_rep,
  group = cases_dep$Department,
  stat = "median",
  binwidth = 0.2
)
```

<img src="stan_figs/NB2_cases_acc.png" alt="NB2_cases_acc" style="zoom:100%;" class="center"/>

## Hierarchical model for `Cumulative/Department`

In order to improve the fit, we fit a model with department-specific intercept term.

So the varying intercept model that we take into account is now:

$$
ln(\lambda_{i,d}) = \alpha_d +  + \beta_{time}\cdot elapsed\_time_i + \beta_{age}\cdot age_i\\
\alpha_d \sim \mathcal{N}(\mu + \beta_{pop}\cdot pop_d + \beta_{sur}\cdot surface_d + \beta_{dens} \cdot density_d, \sigma_{\alpha})\\
y_i \sim \mathcal{Negative Binomial}(\lambda_{i,d}, \phi)
$$
  
The priors used for the above model are the following:

$$
\beta_{time} \sim \mathcal{N}(0.5,1) \\
\beta_{age} \sim \mathcal{N}(0,1) \\
\psi \sim \mathcal{N}(0,1)
$$

being $\psi = [\beta_{pop}, \beta_{sur}, \beta_{dens}]$.

## New dataset

We added the following covariats into the dataset:

  * `People`: millions of inhabitants for each region;
  
  * `Surface`: $km^3$, extent of each region;
  
  * `Density`: $\frac{people}{km^2}$, density of the population in each region.
  
```{r complete_hierarchical_data_fix, warning=FALSE, include=FALSE}
# Million inhabitants per department
cases_dep$People <- rep(0, nrow(cases_dep))
cases_dep[which(cases_dep$`Department ID` == 1),]$People  <- 6.4
cases_dep[which(cases_dep$`Department ID` == 2),]$People  <- 7.4
cases_dep[which(cases_dep$`Department ID` == 3),]$People  <- 1.2
cases_dep[which(cases_dep$`Department ID` == 4),]$People  <- 0.99

cases_dep[which(cases_dep$`Department ID` == 5),]$People  <- 0.4
cases_dep[which(cases_dep$`Department ID` == 6),]$People  <- 1.4
cases_dep[which(cases_dep$`Department ID` == 7),]$People  <- 2.9
cases_dep[which(cases_dep$`Department ID` == 8),]$People  <- 1.04
cases_dep[which(cases_dep$`Department ID` == 9),]$People  <- 0.53
cases_dep[which(cases_dep$`Department ID` == 10),]$People <- 0.94
cases_dep[which(cases_dep$`Department ID` == 11),]$People <- 2.18
cases_dep[which(cases_dep$`Department ID` == 12),]$People <- 1.33
#cases_dep[which(cases_dep$`Department ID` == 13),]$People <- 4.4

# km^2
cases_dep$Surface <- rep(0, nrow(cases_dep))
cases_dep[which(cases_dep$`Department ID` ==1),]$Surface  <- 63600
cases_dep[which(cases_dep$`Department ID` ==2),]$Surface  <- 1775
cases_dep[which(cases_dep$`Department ID` ==3),]$Surface  <- 23189
cases_dep[which(cases_dep$`Department ID` ==4),]$Surface  <- 7888
cases_dep[which(cases_dep$`Department ID` ==5),]$Surface  <- 44640
cases_dep[which(cases_dep$`Department ID` ==6),]$Surface  <- 29308
cases_dep[which(cases_dep$`Department ID` ==7),]$Surface  <- 24210
cases_dep[which(cases_dep$`Department ID` ==8),]$Surface  <- 85635
cases_dep[which(cases_dep$`Department ID` ==9),]$Surface  <- 1845
cases_dep[which(cases_dep$`Department ID` ==10),]$Surface <- 4140
cases_dep[which(cases_dep$`Department ID` ==11),]$Surface <- 30537
cases_dep[which(cases_dep$`Department ID` ==12),]$Surface <- 23562
#cases_dep[which(cases_dep$`Department ID` ==13),]$Surface <- 22195

# Population density inhabitants/km^2
cases_dep$Density <- rep(0, nrow(cases_dep))
cases_dep[which(cases_dep$`Department ID` == 1),]$Density <- 88.06
cases_dep[which(cases_dep$`Department ID` ==2),]$Density  <- 4552
cases_dep[which(cases_dep$`Department ID` ==3),]$Density  <- 93
cases_dep[which(cases_dep$`Department ID` ==4),]$Density  <- 130
cases_dep[which(cases_dep$`Department ID` ==5),]$Density  <- 9.4
cases_dep[which(cases_dep$`Department ID` ==6),]$Density  <- 50
cases_dep[which(cases_dep$`Department ID` ==7),]$Density  <- 99.15
cases_dep[which(cases_dep$`Department ID` ==8),]$Density  <- 12
cases_dep[which(cases_dep$`Department ID` ==9),]$Density  <- 290
cases_dep[which(cases_dep$`Department ID` ==10),]$Density <- 59.16
cases_dep[which(cases_dep$`Department ID` ==11),]$Density <- 72
cases_dep[which(cases_dep$`Department ID` ==12),]$Density <- 56
#cases_dep[which(cases_dep$`Department ID` ==13),]$Density <- 183.04
```

The model is:
  
```{r hierarchical_complete_data, eval=FALSE, warning=FALSE, include=FALSE}
#compile the model 
model3.NB <- stan_model("stan/NB_model3.stan")

People <- cases_dep %>% select(People) %>% unique()
People <- as.vector(People[1])
Density <- cases_dep %>% select(Density) %>% unique()
Density <- as.vector(Density[1])
Surface <- cases_dep %>% select(Surface) %>% unique()
Surface <- as.vector(Surface[1])

dep_data.complete <- cbind(People, Surface, Density)
dep_data.complete <- dep_data.complete %>% as.matrix()

#prepare the new data
data.hier.NB.complete<-
  with(cases_dep,
       list(N = nrow(cases_dep),
            cases = cases_dep$`Cumulative cases/Department`,
            time = cases_dep$`Elapsed time`,
            age = cases_dep$`Mean age`,
            K = 3, 
            J = 12, #13,
            dep_id = cases_dep$`Department ID`,
            dep_data = dep_data.complete
       )
  )

#fit the model 
fit.4 <- sampling(model3.NB, data.hier.NB.complete)
```
  
## Posterior predictive check - hierarchical NB `Cumulative/Department`

```{r hier_posterior_check, echo=TRUE, warning=FALSE, eval=FALSE}
samples_hier <- rstan::extract(fit.4)
y_rep <- samples_hier$y_rep
ppc_dens_overlay(y = data.hier.NB.complete$cases, y_rep[1:200,]) + 
  coord_cartesian(xlim = c(-1, 6000))
```

<img src="stan_figs/hier_cumulative.png" alt="hier_cumulative" style="zoom:100%;" class="center"/>

```{r hier_cum_ecdf, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_ecdf_overlay(cases_dep$`Cumulative cases/Department`, y_rep)
```

<img src="stan_figs/hier_cumulative_ecdf.png" alt="hier_cumulative_ecdf" style="zoom:100%;" class="center"/>

## Residual check - hierarchical NB `Cumulative/Department`

```{r residuals_hier, echo=TRUE, warning=FALSE, eval=FALSE}
mean_inv_phi <- mean(samples_hier$inv_phi)
mean_y_rep <- colMeans(y_rep)
std_residual <- (data.hier.NB.complete$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

<img src="stan_figs/hier_cumulative_res.png" alt="hier_cumulative_res" style="zoom:100%;" class="center"/>

Very few points are now outside the $95\%$ confidence interval.

## Intervals - hierarchical NB `Cumulative/Department`

```{r intervals_hier, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_intervals(
  y = cases_dep$`Cumulative cases/Department`, 
  yrep = y_rep,
  x = cases_dep$`Elapsed time`
) + 
  labs(x = "Days", y = "Cases")
```

<img src="stan_figs/hier_cumulative_intervals.png" alt="hier_cumulative_intervals" style="zoom:100%;" class="center"/>

## Accuracy across departments - hierarchical NB `Cumulative/Department`

```{r deps_hier, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_stat_grouped(
  y = data.hier.NB.complete$cases,
  yrep = y_rep,
  group = cases_dep$Department,
  stat = "median",
  binwidth = 0.2
)
```

<img src="stan_figs/hier_cumulative_acc.png" alt="hier_cumulative_acc" style="zoom:100%;" class="center"/>

We can clearly see that the accuracy across the departments has significantly increased with respect to the previous models.

```{r eval=FALSE, include=FALSE}
#looic has decreased significantly
loo.model.NB.hier<-loo(fit.4)$estimates 
```

## Hierarchical model for `New cases/day`

```{r hierarchical_complete_data_cases, eval=FALSE, warning=FALSE, include=FALSE}
#prepare the new data
data.hier.NB.complete.cases<-
  with(cases_dep,
       list(N = nrow(cases_dep),
            cases = cases_dep$`New cases/day`,
            time = cases_dep$`Elapsed time`,
            age = cases_dep$`Mean age`,
            K = 3, 
            J = 12, #13,
            dep_id = cases_dep$`Department ID`,
            dep_data = dep_data.complete
       )
  )

#fit the model 
fit.4.1 <- sampling(model3.NB, data.hier.NB.complete.cases)
```
  
## Posterior predictive check - hierarchical NB `New cases/day`

```{r hier_posterior_check_cases, echo=TRUE, warning=FALSE, eval=FALSE}
samples_hier <- rstan::extract(fit.4.1)
y_rep <- samples_hier$y_rep
ppc_dens_overlay(y = data.hier.NB.complete.cases$cases, y_rep[1:200,]) + 
  coord_cartesian(xlim = c(-1, 500))
```

<img src="stan_figs/hier_cases.png" alt="hier_cases" style="zoom:100%;" class="center"/>

```{r hier_cum_ecdf_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_ecdf_overlay(cases_dep$`New cases/day`, y_rep)
```

<img src="stan_figs/hier_cases_ecdf.png" alt="hier_cases_ecdf" style="zoom:100%;" class="center"/>

## Residual check - hierarchical NB `New cases/day`

```{r residuals_hier_cases, echo=TRUE, warning=FALSE, eval=FALSE}
mean_inv_phi <- mean(samples_hier$inv_phi)
mean_y_rep <- colMeans(y_rep)
std_residual <- (data.hier.NB.complete.cases$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual, ylim = c(-3, 4)) + hline_at(2) + hline_at(-2)
```

<img src="stan_figs/hier_cases_res.png" alt="hier_cases_res" style="zoom:100%;" class="center"/>

Very few points are now outside the $95\%$ confidence interval.

## Intervals - hierarchical NB `New cases/day`

```{r intervals_hier_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_intervals(
  y = cases_dep$`New cases/day`, 
  yrep = y_rep,
  x = cases_dep$`Elapsed time`
) + 
  labs(x = "Days", y = "Cases")
```

<img src="stan_figs/hier_cases_intervals.png" alt="hier_cases_intervals" style="zoom:100%;" class="center"/>

## Accuracy across departments - hierarchical NB `New cases/day`

```{r deps_hier_cases, echo=TRUE, warning=FALSE, eval=FALSE}
ppc_stat_grouped(
  y = data.hier.NB.complete.cases$cases,
  yrep = y_rep,
  group = cases_dep$Department,
  stat = "median",
  binwidth = 0.2
)
```

<img src="stan_figs/hier_cases_acc.png" alt="hier_cases_acc" style="zoom:100%;" class="center"/>

We can clearly see that the accuracy across the departments has significantly increased with respect to the previous models.

```{r eval=FALSE, include=FALSE}
#looic has decreased significantly
loo.model.NB.hier.cases<-loo(fit.4.1)$estimates 
```

## LOOIC

The Leave-One-Out cross validation is a method for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulation of the parameters values. 

Plot the `looic` to compare models:

```{r bayesian_model_comparison, echo=TRUE, warning=FALSE, eval=FALSE}
loo.all.deps<-c(loo.model.Poisson.cases[3], loo.model.NB.cases[3], loo.model.NB2.cases[3], loo.model.NB.hier.cases[3])

sort.loo.all.deps<- sort.int(loo.all.deps, index.return = TRUE)$x

par(xaxt="n")
plot(sort.loo.all.deps, type="b", xlab="", ylab="LOOIC", main="Model comparison")
par(xaxt="s")
axis(1, c(1:4), c("Poisson", "NB-sl", "NB-ml", 
                  "hier")[sort.int(loo.all.deps,
                    index.return = TRUE)$ix],
                    las=2)
```

<img src="stan_figs/looic.png" alt="looic" style="zoom:100%;" class="center"/>