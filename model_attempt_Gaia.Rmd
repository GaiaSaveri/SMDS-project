---
title: "First Analysis"
author: "Angela Carraro, Giullia Monteiro Milano Oliveira, Gaia Saveri"
date: "3/07/2020"
output:
  html_document:
    highlight: kate
    lightbox: true
    gallery: true
    toc: yes
    toc_depth: 3
  ioslides_presentation:
    highlight: kate
  rmdformats::readthedown:
  include: null
  beamer_presentation:
    highlight: kate
  pdf_document:
    highlight: kate
    keep_tex: yes
    toc: yes
  slide_level: 2
  slidy_presentation:
    fig.height: 3
    fig.width: 4
    highlight: kate
header-includes:
- \usepackage{color}
- \definecolor{Purple}{HTML}{911146}
- \definecolor{Orange}{HTML}{CF4A30}
- \setbeamercolor{alerted text}{fg=Orange}
- \setbeamercolor{frametitle}{bg=Purple}
institute: University of Udine & University of Trieste
graphics: yes
fontsize: 10pt
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center', warning=FALSE, message=FALSE, fig.asp=0.625, dev='png', global.par = TRUE, dev.args=list(pointsize=10), fig.path = 'figs/')
```

```{r setup, include=FALSE}
library(knitr)
local({
  hook_plot = knit_hooks$get('plot')
  knit_hooks$set(plot = function(x, options) {
    paste0('\n\n----\n\n', hook_plot(x, options))
  })
})
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
```

```{r message=FALSE}
library(readr)
library(rstan)
library(dplyr)
library(ggplot2)
library(bayesplot)
library(lubridate)
```

## Load Data


```{r load_data, echo=TRUE, warning=FALSE}
df<-read_csv("data/central_colombia.csv")
ggplot(df, aes(x = date, y = n)) + 
  geom_line(aes(linetype = "New daily cases")) + 
  geom_point(color = "black") + 
  facet_wrap(~dep, scales = "free_y", ncol = 4, labeller = label_both) + 
  scale_y_continuous(name = "", limits = range(df$n)) + 
  scale_linetype_discrete(name = "")
```

Please ignore tha fact that the picture is horrible, I'm starting convincing myself that we should include only the departments that have a "significant" number of cases.. maybe more than 30 cases is enough.

```{r data2, echo=TRUE, warning=FALSE}
data<-read_csv("data/central_colombia_relevant.csv")
data<-data[order(data$dep),]
data<-data[,c(1,5,2,3,4)]
```

## Poisson regression

As a first attempt, we can try to fit a simple Poisson regression:

$$
ln\lambda_i = \alpha + \beta\cdot elapsed\_time_i \\
y_i \sim \mathcal{Poisson}(\lambda_i)
$$

with $i = 1,\dots,83$, and $y_i$ represents the number of cases.

Let's compile the model:

```{r compile_poisson_regression, echo=TRUE, warning=FALSE}
model.Poisson<-stan_model("stan/poisson_regression.stan")
```

Fix things to be able to run the stan model and fit the model:

```{r arrange_poisson, echo=TRUE, warning=FALSE}
#arrange things
model.data<-list(
  N = nrow(data),
  cases = data$n,
  time = data$elapsed_time
)
#str(model.Poisson.data)

#run the model 
fit.model.Poisson<-sampling(model.Poisson, data=model.data)

#inferred parameters
print(fit.model.Poisson, pars=c("alpha", "beta"))
```

Looking at `Rhat` we can see that we have reached the convergence.

```{r first_plot, echo=TRUE, warning=FALSE}
theme_set(bayesplot::theme_default())

mcmc_scatter(as.matrix(fit.model.Poisson, pars=c("alpha", "beta") ), alpha=0.2)
```

Check the posterior:

```{r poisson_posterior, echo=TRUE, warning=FALSE}
y_rep<-as.matrix(fit.model.Poisson, pars="y_rep")
ppc_dens_overlay(y = model.data$cases, y_rep[1:200,]) 
```

The model is not able to capture low and high numbers of new cases.

The fit is not satisfactory, it is probably due to overdispersion, we can check the residuals to confirm this hypothesis: 

```{r first_residual, echo=TRUE, warning=FALSE}
#in this way we check the standardized residuals
mean_y_rep<-colMeans(y_rep)
std_residual<-(model.data$cases - mean_y_rep) / sqrt(mean_y_rep)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

The variance of the residuals increases as the predicted value increase. The standardized residuals should have mean 0 and standard deviation 1 (hence the lines at +2 and -2 indicates approximate 95% error bounds). The variance of the standardized residuals is much greater than 1, indicating a large amount of overdispersion. 

Classically the problem of having overdispersed data is solved using the negative binomial model instead of the Poisson one. To be continued!

## Negative binomial model

In order to deal with the problem of overdispersed data, we can try to fit the following Negative Binomial model:

$$
ln\lambda_i = \alpha + \beta\cdot elapsed\_time_i \\
y_i \sim \mathcal{Negative Binomial}(\lambda_i, \phi)
$$

Where the parameter $\phi$ is called *precision* and it is such that:

$$
E[y_i] = \lambda \\  Var[y_i] = \lambda + \frac{\lambda^2}{\phi}
$$

again $i=1,\dots,83$. As $\phi \rightarrow \infty$ the negative binomial approaches the Poisson distribution.

Let's compile and run the stan model: 

```{r compile_nb, echo=TRUE, warning=FALSE, eval=FALSE}
#compile
model.NB<-stan_model("stan/negative_binomial.stan")
#fit
fit.model.NB<-sampling(model.NB, data=model.data)
#inferred parameters
print(fit.model.NB, pars=c("alpha", "beta"))
```

Chains have reached convergence, let's check the fit:

```{r NB_posterior, echo=TRUE, warning=FALSE}
#posterior predictive chiecking
samples_NB<-rstan::extract(fit.model.NB)
y_rep<-samples_NB$y_rep
ppc_dens_overlay(y = model.data$cases, y_rep[1:200,]) 
```

The fit seems better now! Both the tails and the peak are well captured by the model now. 

Let's look again at the standardized residuals:

```{r NB_residuals, echo=TRUE, warning=FALSE}
mean_inv_phi<-mean(samples_NB$inv_phi)
mean_y_rep<-colMeans(y_rep)
std_residual<-(model.data$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

The situation has improved a lot, we still have a few large standardized residual. 

Maybe because the situation across regions is very different, let's check!

```{r regions, echo=TRUE, warning=FALSE}
ppc_stat_grouped(
  y = model.data$cases,
  yrep = y_rep,
  group = data$dep,
  stat = "mean",
  binwidth = 0.2
)
```

Maybe we should take into account the difference across departments, since most prediction are not accurate!

```{r another_check, echo=TRUE, warning=FALSE}
data
ppc_intervals(
  y = data$n, 
  yrep = y_rep,
  x = data$elapsed_time
) + 
  labs(x = "Days", y = "Cases")
```

We still have some large number of cases that the model consider extremely unlikely events. 

## Hierarchical modeling

Consider the following model:

$$
ln\lambda_{d,i} = \alpha_d + \beta\cdot elapsed\_time_i \\
\alpha_{d} \sim \mathcal{N}(\mu + \beta_{dep}\cdot dep\_id_d, \sigma) \\
y_{d,i} \sim \mathcal{Negative Binomial}(\lambda_i, \phi)
$$

where $d$ stands for department, and $\alpha_d$ is an intercept that veries from department  to department. 

Maybe we could include some more info about departemnts, e.g. the total number of people living there, or the density of inhabitants, the total surface.. 

As first thing we should convert the variable `dep` from a categorical to a numerical one:

```{r fix, echo=TRUE, warning=FALSE}
data <- data %>%
  mutate(dep_idx = factor(dep, levels=unique(dep)),
         dep_id = as.integer(dep_idx)) %>%
  select(-dep_idx)
data<-data[,c(1,2,3,6,4,5)]
```

We can try to add the number of inhabitants (in million people) of each department:

```{r add_inhabitants, echo=TRUE, warning=FALSE}
data$people<-rep(0, nrow(data))

data[which(data$dep_id==1),]$people<-6.4
data[which(data$dep_id==2),]$people<-7.4
data[which(data$dep_id==3),]$people<-2.9
data[which(data$dep_id==4),]$people<-0.94
data[which(data$dep_id==5),]$people<-4.4

cc<-read_csv("data/colombia_covid.csv")
tail(cc)
central.colombia.dep<-c("Bogotá D.C.", "Cundinamarca",  "Valle del Cauca", "Risaralda", "Antioquia")
central.colombia.rows<-which(cc$`Departamento o Distrito` %in% central.colombia.dep)
cc<-cc[central.colombia.rows,]

bogota_mean_age<-cc[which(cc$`Departamento o Distrito`=="Bogotá D.C."),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
cundinamarca_mean_age<-cc[which(cc$`Departamento o Distrito`=="Cundinamarca"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
valle_cauca_mean_age<-cc[which(cc$`Departamento o Distrito`=="Valle del Cauca"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
risaralda_mean_age<-cc[which(cc$`Departamento o Distrito`=="Risaralda"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
antioquia_mean_age<-cc[which(cc$`Departamento o Distrito`=="Antioquia"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
data$age<-rep(0,nrow(data))

data[which(data$dep_id==1),]$age<-unname(unlist(c(antioquia_mean_age[2])))
data[which(data$dep_id==2),]$age<-unname(unlist(c(bogota_mean_age[2])))
data[which(data$dep_id==3),]$age<-unname(unlist(c(cundinamarca_mean_age[2])))
data[which(data$dep_id==4),]$age<-unname(unlist(c(risaralda_mean_age[2])))
data[which(data$dep_id==5),]$age<-unname(unlist(c(valle_cauca_mean_age[2])))
```

We can try to include these new variables in the model, for example (varying intercept model, considering people as exposure term):

$$
ln\lambda_{i,d} = \alpha_d + \beta_{time}\cdot elapsed\_time_i + \beta_{age}age_i + log(people_i) \\
\alpha_d \sim \mathcal{N}(\mu, \sigma)\\
y_i \sim \mathcal{Negative Binomial}(\lambda_{i,d}, \phi)
$$

where $d$ stands for department. 

Try to compile and run:

```{r model_more_info, echo=TRUE, warning=FALSE}
model2.NB<-stan_model("stan/NB_model2.stan")

#arrange things
model.data2<-list(
  N = nrow(data),
  cases = data$n,
  time = data$elapsed_time,
  age = data$age,
  log_people = log(data$people*10)
  #D = 5,
  #dep = data$dep_id,
  #id = data$dep_id
)

#fit
fit.model2.NB<-sampling(model2.NB, model.data2)

#posterior predictive chiecking
samples_NB2<-rstan::extract(fit.model2.NB)
y_rep<-samples_NB2$y_rep
#ppc_dens_overlay(y = model .data2$cases, y_rep[1:200,]) 
ppc_stat_grouped(
  y = model.data2$cases,
  yrep = y_rep,
  group = data$dep,
  stat = "mean",
  binwidth = 0.2
)
ppc_intervals(
  y = data$n, 
  yrep = y_rep,
  x = data$elapsed_time
) + 
  labs(x = "Days", y = "Cases")
```

## Hierarchical modeling 

We include an intercept term which should take into account the difference among regions. 

So the model (varying intercept model) that we take into account is now:

$$
ln\lambda_{i,d} = \alpha_d + \beta\cdot elapsed\_time_i \\
\alpha_d \sim \mathcal{N}(\mu, \sigma)\\
y_i \sim \mathcal{Negative Binomial}(\lambda_{i,d}, \phi)
$$

where $d$ stands for department. 

```{r hier_first, echo=TRUE, warning=FALSE}
data<- data %>%  
  mutate(dep_idx = factor(dep, levels = unique(dep)),
          dep_id = as.integer(dep_idx)) %>%
  select(-dep_idx)
data<-data[,c(1,2,3,6,4,5)]
data
length(unique(data$dep_id))
#compile
model2.NB<-stan_model("stan/NB_model2.stan")

#modify model data to add necessary things
model2.data<-with(data,
                  list(D=length(unique(data$dep_id)),
                       N=nrow(data),
                       cases = n,
                       dep = data$dep_id,
                       time = data$elapsed_time
                       )
)
#fit
fit.model2.NB<-sampling(model2.NB, model2.data)
#save sampling
samples_NB2<-rstan::extract(fit.model.NB)
y_rep<-samples_NB2$y_rep
ppc_dens_overlay(y = model2.data$cases, y_rep[1:200,]) 
```

Let's check if there is difference in the accuracy across departments with respect to the previous model:

```{r accuracy_dep, echo=TRUE, warning=FALSE}
ppc_stat_grouped(
  y = model2.data$cases,
  yrep = y_rep,
  group = data$dep,
  stat = "mean",
  binwidth = 0.5
)
```

Unfortunately the situation has not changed under this point of view :(

Let's check the residuals:

```{r NB2_residuals, echo=TRUE, warning=FALSE}
mean_inv_phi<-mean(samples_NB2$inv_phi)
mean_y_rep<-colMeans(y_rep)
std_residual<-(model.data$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

very few points are outside the 95% confidence interval now!


## Reference

At the moment I'm using as a reference the book `Hierarchical_Models.pdf` in the folder `books`.. and a lot of Google!
<!-- knitr::knit("first_analysis.Rmd", tangle = TRUE, output ="first_analysis.R") -->
