---
title: "First Analysis"
author: "Angela Carraro, Giullia Monteiro Milano Oliveira, Gaia Saveri"
date: "3/07/2020"
output:
  html_document:
    highlight: kate
    lightbox: true
    gallery: true
    toc: yes
    toc_depth: 3
  ioslides_presentation:
    highlight: kate
  rmdformats::readthedown:
  include: null
  beamer_presentation:
    highlight: kate
  pdf_document:
    highlight: kate
    keep_tex: yes
    toc: yes
  slide_level: 2
  slidy_presentation:
    fig.height: 3
    fig.width: 4
    highlight: kate
header-includes:
- \usepackage{color}
- \definecolor{Purple}{HTML}{911146}
- \definecolor{Orange}{HTML}{CF4A30}
- \setbeamercolor{alerted text}{fg=Orange}
- \setbeamercolor{frametitle}{bg=Purple}
institute: University of Udine & University of Trieste
graphics: yes
fontsize: 10pt
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center', warning=FALSE, message=FALSE, fig.asp=0.625, dev='png', global.par = TRUE, dev.args=list(pointsize=10), fig.path = 'figs/')
```

```{r setup, include=FALSE}
library(knitr)
local({
  hook_plot = knit_hooks$get('plot')
  knit_hooks$set(plot = function(x, options) {
    paste0('\n\n----\n\n', hook_plot(x, options))
  })
})
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
```

```{r message=FALSE}
library(readr)
library(loo)
library(rstan)
library(dplyr)
library(ggplot2)
library(bayesplot)
library(lubridate)
```

## Load Data


```{r load_data, echo=TRUE, warning=FALSE}
df<-read_csv("data/central_colombia.csv")
ggplot(df, aes(x = date, y = n)) + 
  geom_line(aes(linetype = "New daily cases")) + 
  geom_point(color = "black") + 
  facet_wrap(~dep, scales = "free_y", ncol = 4, labeller = label_both) + 
  scale_y_continuous(name = "", limits = range(df$n)) + 
  scale_linetype_discrete(name = "")
```

Please ignore tha fact that the picture is horrible, I'm starting convincing myself that we should include only the departments that have a "significant" number of cases.. maybe more than 30 cases is enough.

```{r data2, echo=TRUE, warning=FALSE}
data<-read_csv("data/central_colombia_relevant.csv")
data<-data[order(data$dep),]
data<-data[,c(1,5,2,3,4)]
data
```

## Poisson regression

As a first attempt, we can try to fit a simple Poisson regression:

$$
ln\lambda_i = \alpha + \beta\cdot elapsed\_time_i \\
y_i \sim \mathcal{Poisson}(\lambda_i)
$$

with $i = 1,\dots,83$, and $y_i$ represents the number of cases.

In this model the likelihood is given the Poisson probability mass function.

In the `stan` model we use the function `poisson_log_rng` to describe the distribution of $y_i$, namely the number of cases each day and the function `poisson_log_lpmf` to specify the likelihood.

The data that we use to fit this model are composed by the following attributes:

  * `n`: response variable. Number of cases reported each day in each department;
  
  * `elapsed_time`: days passed after the first day in which a case has been reported (the $6^{th}$ of March).

Let's compile the model:

```{r compile_poisson_regression, echo=TRUE, warning=FALSE}
model.Poisson<-stan_model("stan/poisson_regression.stan")
```

Fix things to be able to run the stan model and fit the model:

```{r arrange_poisson, echo=TRUE, warning=FALSE}
#arrange things
model.data<-list(
  N = nrow(data),
  cases = data$n,
  time = data$elapsed_time
)
#str(model.Poisson.data)

#run the model 
fit.model.Poisson<-sampling(model.Poisson, data=model.data)

#inferred parameters
print(fit.model.Poisson, pars=c("alpha", "beta"))

loo.model.Poisson<-loo(fit.model.Poisson)$estimates
loo.model.Poisson
```

Looking at `Rhat` we can see that we have reached the convergence.

```{r first_plot, echo=TRUE, warning=FALSE}
theme_set(bayesplot::theme_default())

mcmc_scatter(as.matrix(fit.model.Poisson, pars=c("alpha", "beta") ), alpha=0.2)
```

Check the posterior:

```{r poisson_posterior, echo=TRUE, warning=FALSE}
y_rep<-as.matrix(fit.model.Poisson, pars="y_rep")
ppc_dens_overlay(y = model.data$cases, y_rep[1:200,]) 
```

The model is not able to capture low and high numbers of new cases.

The fit is not satisfactory, it is probably due to overdispersion, we can check the residuals to confirm this hypothesis: 

```{r first_residual, echo=TRUE, warning=FALSE}
#in this way we check the standardized residuals
mean_y_rep<-colMeans(y_rep)
std_residual<-(model.data$cases - mean_y_rep) / sqrt(mean_y_rep)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

The variance of the residuals increases as the predicted value increase. The standardized residuals should have mean 0 and standard deviation 1 (hence the lines at +2 and -2 indicates approximate 95% error bounds). The variance of the standardized residuals is much greater than 1, indicating a large amount of overdispersion. 

Classically the problem of having overdispersed data is solved using the negative binomial model instead of the Poisson one. To be continued!

## Negative binomial model

In order to deal with the problem of overdispersed data, we can try to fit the following Negative Binomial model:

$$
ln\lambda_i = \alpha + \beta\cdot elapsed\_time_i \\
y_i \sim \mathcal{Negative Binomial}(\lambda_i, \phi)
$$

Where the parameter $\phi$ is called *precision* and it is such that:

$$
E[y_i] = \lambda \\  Var[y_i] = \lambda + \frac{\lambda^2}{\phi}
$$

again $i=1,\dots,83$. As $\phi \rightarrow \infty$ the negative binomial approaches the Poisson distribution.

The `stan` function that we use here are `neg_binomial_2_log_rng` to specify the distribution of $y_i$ and the function `neg_binomial_2_log_lpmf` for the likelihood. These are log-parametrization of the Negative Binomial function, that allow to specify the model using as parameters the log-location (what we called $ln\lambda$) and the inverse overdispersion (here $\frac{1}{\phi}$).

Data are the same used for the Poisson regression above.

Let's compile and run the stan model: 

```{r compile_nb, echo=TRUE, warning=FALSE, eval=FALSE}
#compile
model.NB<-stan_model("stan/negative_binomial.stan")
#fit
fit.model.NB<-sampling(model.NB, data=model.data)
#inferred parameters
print(fit.model.NB, pars=c("alpha", "beta"))
```

Chains have reached convergence, let's check the fit:

```{r NB_posterior, echo=TRUE, warning=FALSE}
#posterior predictive chiecking
samples_NB<-rstan::extract(fit.model.NB)
y_rep<-samples_NB$y_rep
ppc_dens_overlay(y = model.data$cases, y_rep[1:200,]) 
```

The fit seems better now! Both the tails and the peak are well captured by the model now. 

Let's look again at the standardized residuals:

```{r NB_residuals, echo=TRUE, warning=FALSE}
mean_inv_phi<-mean(samples_NB$inv_phi)
mean_y_rep<-colMeans(y_rep)
std_residual<-(model.data$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)
```

The situation has improved a lot, we still have a few large standardized residual. 

Maybe because the situation across regions is very different, let's check!

```{r regions, echo=TRUE, warning=FALSE}
ppc_stat_grouped(
  y = model.data$cases,
  yrep = y_rep,
  group = data$dep,
  stat = "mean",
  binwidth = 0.2
)
```

Maybe we should take into account the difference across departments, since most prediction are not accurate!

```{r another_check, echo=TRUE, warning=FALSE}
ppc_intervals(
  y = data$n, 
  yrep = y_rep,
  x = data$elapsed_time
) + 
  labs(x = "Days", y = "Cases")
```

We still have some large number of cases that the model consider extremely unlikely events.

```{r log_lik, echo=TRUE, warning=FALSE}
loo.model.NB<-loo(fit.model.NB)$estimates
loo.model.NB
```

As first thing we should convert the variable `dep` from a categorical to a numerical one:

```{r fix, echo=TRUE, warning=FALSE}
data <- data %>%
  mutate(dep_idx = factor(dep, levels=unique(dep)),
         dep_id = as.integer(dep_idx)) %>%
  select(-dep_idx)
data<-data[,c(1,2,3,6,4,5)]
```

We can try to add the number of inhabitants (in million people) of each department:

```{r add_inhabitants, echo=TRUE, warning=FALSE}
data$people<-rep(0, nrow(data))

data[which(data$dep_id==1),]$people<-6.4
data[which(data$dep_id==2),]$people<-7.4
data[which(data$dep_id==3),]$people<-2.9
data[which(data$dep_id==4),]$people<-0.94
data[which(data$dep_id==5),]$people<-4.4

cc<-read_csv("data/colombia_covid.csv")
central.colombia.dep<-c("Bogotá D.C.", "Cundinamarca",  "Valle del Cauca", "Risaralda", "Antioquia")
central.colombia.rows<-which(cc$`Departamento o Distrito` %in% central.colombia.dep)
cc<-cc[central.colombia.rows,]

bogota_mean_age<-cc[which(cc$`Departamento o Distrito`=="Bogotá D.C."),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
cundinamarca_mean_age<-cc[which(cc$`Departamento o Distrito`=="Cundinamarca"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
valle_cauca_mean_age<-cc[which(cc$`Departamento o Distrito`=="Valle del Cauca"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
risaralda_mean_age<-cc[which(cc$`Departamento o Distrito`=="Risaralda"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
antioquia_mean_age<-cc[which(cc$`Departamento o Distrito`=="Antioquia"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
data$age<-rep(0,nrow(data))

data[which(data$dep_id==1),]$age<-unname(unlist(c(antioquia_mean_age[2])))
data[which(data$dep_id==2),]$age<-unname(unlist(c(bogota_mean_age[2])))
data[which(data$dep_id==3),]$age<-unname(unlist(c(cundinamarca_mean_age[2])))
data[which(data$dep_id==4),]$age<-unname(unlist(c(risaralda_mean_age[2])))
data[which(data$dep_id==5),]$age<-unname(unlist(c(valle_cauca_mean_age[2])))

```

We can try to include these new variables in the model, for example (varying intercept model, considering people as exposure term):

$$
ln\lambda_i = \alpha + \beta_{time}\cdot elapsed\_time_i + \beta_{age}\cdot age \\
y_i \sim \mathcal{Negative Binomial}(\lambda_i, \phi)
$$

where $d$ stands for department. 

In this model we add a covariate wrt the previous model:

  * `age`: mean age of the infected people each day in each department. 

Try to compile and run:

```{r model_more_info, echo=TRUE, warning=FALSE}
model2.NB<-stan_model("stan/NB_model2.stan")

#arrange things
model.data2<-list(
  N = nrow(data),
  cases = data$n,
  time = data$elapsed_time,
  age = data$age
)

#fit
fit.model2.NB<-sampling(model2.NB, model.data2)

#posterior predictive chiecking
samples_NB2<-rstan::extract(fit.model2.NB)
y_rep<-samples_NB2$y_rep
ppc_dens_overlay(y = model.data2$cases, y_rep[1:200,]) 
ppc_stat_grouped(
  y = model.data2$cases,
  yrep = y_rep,
  group = data$dep,
  stat = "mean",
  binwidth = 0.2
)
ppc_intervals(
  y = data$n, 
  yrep = y_rep,
  x = data$elapsed_time
) + 
  labs(x = "Days", y = "Cases")

loo.model.NB2<-loo(fit.model2.NB)$estimates
loo.model.NB2
```

```{r dep_surface, echo=TRUE, warning=FALSE}
#km^2
antioquia_surface<-63600
bogota_surface<-1775
cundinamarca_surface<-24210
risaralda_surface<-4140
valle_cauca_surface<-22195

#population density inhabitants/km^2
antioquia_density<-88.06
bogota_density<-4552
cundinamarca_density<-99.15
risaralda_density<-59.16
valle_cauca_density<-183.04

data$surface<-rep(0, nrow(data))
data$density<-rep(0, nrow(data))

data[which(data$dep_id==1),]$surface<-antioquia_surface
data[which(data$dep_id==2),]$surface<-bogota_surface
data[which(data$dep_id==3),]$surface<-cundinamarca_surface
data[which(data$dep_id==4),]$surface<-risaralda_surface
data[which(data$dep_id==5),]$surface<-valle_cauca_surface

data[which(data$dep_id==1),]$density<-antioquia_density
data[which(data$dep_id==2),]$density<-bogota_density
data[which(data$dep_id==3),]$density<-cundinamarca_density
data[which(data$dep_id==4),]$density<-risaralda_density
data[which(data$dep_id==5),]$density<-valle_cauca_density

```

## Hierarchical modeling 

We include an intercept term which should take into account the difference among regions. 

So the model (varying intercept model) that we take into account is now:

$$
ln\lambda_{i,d} = \alpha_d +  + \beta_{time}\cdot elapsed\_time_i + \beta_{age}\cdot age_i\\
\alpha_d \sim \mathcal{N}(\mu + \beta_{pop}\cdot pop_d + \beta_{sur}\cdot surface_d + \beta_{dens} \cdot density_d, \sigma_{\alpha})\\
y_i \sim \mathcal{Negative Binomial}(\lambda_{i,d}, \phi)
$$

where $d$ stands for department. 

We added the following covariats into the dataset (taken from Wikipedia pages of the different regions):

  * `people`: millions of inhabitants for each region;
  
  * `surface`: in $km^3$, extent of each region;
  
  * `density`: $\frac{people}{km^2}$, density of the population in each region.
  
We did so because we think that these geographical data are useful to describe the dynamics of the epidemic, and the difference in the spread of the disease across different departments of Central Colombia. 


```{r hier_first, echo=TRUE, warning=FALSE}
#compile the model 
model3.NB<-stan_model("stan/NB_model3.stan")

dep_data<-data %>%
  select(
    dep_id,
    people,
    surface,
    density
  ) %>%
  unique() %>%
  arrange(dep_id) %>%
  select(-dep_id) %>%
  as.matrix()

#prepare the new data
data.hier.NB<-
  with(data,
       list(N = nrow(data),
            cases = data$n,
            time = data$elapsed_time,
            age = data$age,
            K=3, 
            J=5,
            dep_id = data$dep_id,
            dep_data = dep_data
       )
  )

#fit the model 
fit.hier.NB<-sampling(model3.NB, data.hier.NB)

#extract --> rhat is good for all chains
sampling.hier.NB<-rstan::extract(fit.hier.NB)
print(fit.hier.NB, pars=c('phi','beta_t','beta_a','alpha_d','sigma_alpha', 'mu'))

#posterior predictive chiecking
y_rep<-sampling.hier.NB$y_rep
ppc_dens_overlay(y = data.hier.NB$cases, y_rep[1:200,]) 

#accuracy across departments
ppc_stat_grouped(
  y = data.hier.NB$cases,
  yrep = y_rep,
  group = data$dep,
  stat = "mean",
  binwidth = 0.2
)

ppc_intervals(
  y = data$n, 
  yrep = y_rep,
  x = data$elapsed_time
) + 
  labs(x = "Days", y = "Cases")

loo.model.NB.hier<-loo(fit.hier.NB)$estimates
loo.model.NB.hier
```

Both the accuracy across departments and the intervals have improved a lot wrt to the previous models!

Let's check the residuals:

```{r NB2_residuals, echo=TRUE, warning=FALSE}
mean_inv_phi<-mean(sampling.hier.NB$inv_phi)
mean_y_rep<-colMeans(y_rep)
std_residual<-(data.hier.NB$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual, xlab = "predicted", ylab="standardized residuals") + hline_at(2) + hline_at(-2)
```

very few points (only two) are outside the 95% confidence interval now! 

## Attempt with the dataset with all departments

```{r fix_complete_data, echo=TRUE, warning=FALSE}
df<-df[order(df$dep),]
df<-df[,c(1,4,2,3)]
df
#try with the poisson model
model.Poisson<-stan_model("stan/poisson_regression.stan")

Poisson.data.complete<-list(
  N = nrow(df),
  cases = df$n,
  time = df$elapsed_time
)

#run the model 
fit.Poisson.complete<-sampling(model.Poisson, data=Poisson.data.complete)

#inferred parameters
print(fit.Poisson.complete, pars=c("alpha", "beta"))

loo.model.Poisson.complete<-loo(fit.Poisson.complete)$estimates
loo.model.Poisson.complete
#looic is higher than the one in the case of only the 5 more relevant deprtments

y_rep<-as.matrix(fit.Poisson.complete, pars="y_rep")
ppc_dens_overlay(y = Poisson.data.complete$cases, y_rep[1:200,]) 
```

Here we see that the fit is not acceptable, the generated samplings are not able to capture the peak of the incidence curve, nor the tail, which is much longer than the one predicted.

We proceed as before and try to fit a negative binomial model.

```{r neg_bin_complete, echo=TRUE, warning=FALSE}
#compile the NB model
model.NB<-stan_model("stan/negative_binomial.stan")
#fit
fit.NB.complete<-sampling(model.NB, data=Poisson.data.complete)
#inferred parameters
print(fit.NB.complete, pars=c("alpha", "beta"))

#posterior predictive chiecking
samples.NB.complete<-rstan::extract(fit.NB.complete)
y_rep<-samples.NB.complete$y_rep
ppc_dens_overlay(y = Poisson.data.complete$cases, y_rep[1:200,])

#check residuals --> a lot of point are misplaced!
mean_inv_phi<-mean(samples.NB.complete$inv_phi)
mean_y_rep<-colMeans(y_rep)
std_residual<-(Poisson.data.complete$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)

#check looic --> decreased wrt to the poisson case
loo.NB.complete<-loo(fit.NB.complete)$estimates
loo.NB.complete
```

Now, as we did before, we try to add the age as covariat:

```{r fix_data_complete, echo=TRUE, warning=FALSE}
df <- df %>%
  mutate(dep_idx = factor(dep, levels=unique(dep)),
         dep_id = as.integer(dep_idx)) %>%
  select(-dep_idx)
df<-df[,c(1,2,3,5,4)]

cc<-read_csv("data/colombia_covid.csv")
central.colombia.dep<-c("Bogotá D.C.", "Tolima", "Cundinamarca", "Meta", "Boyacá", "Quindío", "Cauca", "Valle del Cauca", "Risaralda", "Caldas", "Boyacá", "Antioquia", "Santander", "Casanare")
central.colombia.rows<-which(cc$`Departamento o Distrito` %in% central.colombia.dep)
cc<-cc[central.colombia.rows,]

bogota_mean_age<-cc[which(cc$`Departamento o Distrito`=="Bogotá D.C."),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
cundinamarca_mean_age<-cc[which(cc$`Departamento o Distrito`=="Cundinamarca"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
valle_cauca_mean_age<-cc[which(cc$`Departamento o Distrito`=="Valle del Cauca"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
risaralda_mean_age<-cc[which(cc$`Departamento o Distrito`=="Risaralda"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
antioquia_mean_age<-cc[which(cc$`Departamento o Distrito`=="Antioquia"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))

boyaca_mean_age<-cc[which(cc$`Departamento o Distrito`=="Boyacá"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
caldas_mean_age<-cc[which(cc$`Departamento o Distrito`=="Caldas"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
casanare_mean_age<-cc[which(cc$`Departamento o Distrito`=="Casanare"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
cauca_mean_age<-cc[which(cc$`Departamento o Distrito`=="Cauca"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
meta_mean_age<-cc[which(cc$`Departamento o Distrito`=="Meta"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
quindio_mean_age<-cc[which(cc$`Departamento o Distrito`=="Quindío"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
santander_mean_age<-cc[which(cc$`Departamento o Distrito`=="Santander"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))
tolima_mean_age<-cc[which(cc$`Departamento o Distrito`=="Tolima"),] %>% 
  group_by(`Fecha de diagnóstico`) %>% 
  summarise_at(vars(Edad), funs(mean(.,na.rm=TRUE)))

df$age<-rep(0,nrow(df))

df[which(df$dep_id==1),]$age<-unname(unlist(c(antioquia_mean_age[2])))
df[which(df$dep_id==2),]$age<-unname(unlist(c(bogota_mean_age[2])))
df[which(df$dep_id==3),]$age<-unname(unlist(c(boyaca_mean_age[2])))
df[which(df$dep_id==4),]$age<-unname(unlist(c(caldas_mean_age[2])))
df[which(df$dep_id==5),]$age<-unname(unlist(c(casanare_mean_age[2])))
df[which(df$dep_id==6),]$age<-unname(unlist(c(cauca_mean_age[2])))
df[which(df$dep_id==7),]$age<-unname(unlist(c(cundinamarca_mean_age[2])))
df[which(df$dep_id==8),]$age<-unname(unlist(c(meta_mean_age[2])))
df[which(df$dep_id==9),]$age<-unname(unlist(c(quindio_mean_age[2])))
df[which(df$dep_id==10),]$age<-unname(unlist(c(risaralda_mean_age[2])))
df[which(df$dep_id==11),]$age<-unname(unlist(c(santander_mean_age[2])))
df[which(df$dep_id==12),]$age<-unname(unlist(c(tolima_mean_age[2])))
df[which(df$dep_id==13),]$age<-unname(unlist(c(valle_cauca_mean_age[2])))


model2.NB<-stan_model("stan/NB_model2.stan")

#arrange things
model.df2<-list(
  N = nrow(df),
  cases = df$n,
  time = df$elapsed_time,
  age = df$age
)

#fit
fit.model2.NB.complete<-sampling(model2.NB, model.df2)

#posterior predictive chiecking
samples.NB2.complete<-rstan::extract(fit.model2.NB.complete)
y_rep<-samples.NB2.complete$y_rep
ppc_dens_overlay(y = model.df2$cases, y_rep[1:200,]) 

#some points are out of the interval!
ppc_intervals(
  y = df$n, 
  yrep = y_rep,
  x = df$elapsed_time
) + 
  labs(x = "Days", y = "Cases")

#check residuals --> still a lot of point are misplaced!
mean_inv_phi<-mean(samples.NB2.complete$inv_phi)
mean_y_rep<-colMeans(y_rep)
std_residual<-(model.df2$cases - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean_inv_phi)
qplot(mean_y_rep, std_residual) + hline_at(2) + hline_at(-2)

loo.model.NB2.complete<-loo(fit.model2.NB.complete)$estimates
loo.model.NB2.complete #--> didn't improved much :(
```

We can finally try to fit the hierarchical model:

```{r complete_hierarchical_data_fix, echo=TRUE, warning=FALSE}
#million inhabitants per department
df$people<-rep(0, nrow(df))

df[which(df$dep_id==1),]$people<-6.4
df[which(df$dep_id==2),]$people<-7.4
df[which(df$dep_id==3),]$people<-1.2
df[which(df$dep_id==4),]$people<-0.99
df[which(df$dep_id==5),]$people<-0.4
df[which(df$dep_id==6),]$people<-1.4
df[which(df$dep_id==7),]$people<-2.9
df[which(df$dep_id==8),]$people<-1.04
df[which(df$dep_id==9),]$people<-0.53
df[which(df$dep_id==10),]$people<-0.94
df[which(df$dep_id==11),]$people<-2.18
df[which(df$dep_id==12),]$people<-1.33
df[which(df$dep_id==13),]$people<-4.4

#km^2
antioquia_surface<-63600
bogota_surface<-1775
boyaca_surface<-23189
caldas_surface<-7888
casanare_surface<-44640
cauca_surface<-29308
cundinamarca_surface<-24210
meta_surface<-85635
quindio_surface<-1845
risaralda_surface<-4140
santander_surface<-30537
tolima_surface<-23562
valle_cauca_surface<-22195

#population density inhabitants/km^2
antioquia_density<-88.06
bogota_density<-4552
boyaca_density<-93
caldas_density<-130
casanare_density<-9.4
cauca_density<-50
cundinamarca_density<-99.15
meta_density<-density<-12
quindio_density<-290
risaralda_density<-59.16
santander_density<-72
tolima_density<-56
valle_cauca_density<-183.04

df$surface<-rep(0, nrow(df))
df$density<-rep(0, nrow(df))

df[which(df$dep_id==1),]$surface<-antioquia_surface
df[which(df$dep_id==2),]$surface<-bogota_surface
df[which(df$dep_id==3),]$surface<-boyaca_surface
df[which(df$dep_id==4),]$surface<-caldas_surface
df[which(df$dep_id==5),]$surface<-casanare_surface
df[which(df$dep_id==6),]$surface<-cauca_surface
df[which(df$dep_id==7),]$surface<-cundinamarca_surface
df[which(df$dep_id==8),]$surface<-meta_surface
df[which(df$dep_id==9),]$surface<-quindio_surface
df[which(df$dep_id==10),]$surface<-risaralda_surface
df[which(df$dep_id==11),]$surface<-santander_surface
df[which(df$dep_id==12),]$surface<-tolima_surface
df[which(df$dep_id==13),]$surface<-valle_cauca_surface

df[which(df$dep_id==1),]$density<-antioquia_density
df[which(df$dep_id==2),]$density<-bogota_density
df[which(df$dep_id==3),]$density<-boyaca_density
df[which(df$dep_id==4),]$density<-caldas_density
df[which(df$dep_id==5),]$density<-casanare_density
df[which(df$dep_id==6),]$density<-cauca_density
df[which(df$dep_id==7),]$density<-cundinamarca_density
df[which(df$dep_id==8),]$density<-meta_density
df[which(df$dep_id==9),]$density<-quindio_density
df[which(df$dep_id==10),]$density<-risaralda_density
df[which(df$dep_id==11),]$density<-santander_density
df[which(df$dep_id==12),]$density<-tolima_density
df[which(df$dep_id==13),]$density<-valle_cauca_density
```

We can finally try to fit the hierarchical model to the complete dataset:

```{r hierarchical_complete_data, echo=TRUE, warning=FALSE}
#compile the model 
model3.NB<-stan_model("stan/NB_model3.stan")

dep_data.complete<-df %>%
  select(
    dep_id,
    people,
    surface,
    density
  ) %>%
  unique() %>%
  arrange(dep_id) %>%
  select(-dep_id) %>%
  as.matrix()

#prepare the new data
data.hier.NB.complete<-
  with(df,
       list(N = nrow(df),
            cases = df$n,
            time = df$elapsed_time,
            age = df$age,
            K=3, 
            J=13,
            dep_id = df$dep_id,
            dep_data = dep_data.complete
       )
  )

#fit the model 
fit.hier.NB.complete<-sampling(model3.NB, data.hier.NB.complete)

#extract --> rhat is good for all chains
sampling.hier.NB.complete<-rstan::extract(fit.hier.NB.complete)
print(fit.hier.NB.complete, pars=c('phi','beta_t','beta_a','alpha_d','sigma_alpha', 'mu'))

#posterior predictive chiecking
y_rep<-sampling.hier.NB.complete$y_rep
ppc_dens_overlay(y = data.hier.NB.complete$cases, y_rep[1:200,]) 

#accuracy across departments
ppc_stat_grouped(
  y = data.hier.NB.complete$cases,
  yrep = y_rep,
  group = df$dep,
  stat = "mean",
  binwidth = 0.2
)

ppc_intervals(
  y = df$n, 
  yrep = y_rep,
  x = df$elapsed_time
) + 
  labs(x = "Days", y = "Cases")

#looic has decreased significantly
loo.model.NB.hier.complete<-loo(fit.hier.NB.complete)$estimates
loo.model.NB.hier.complete
```

## LOOIC

The Leave-One-Out cross validation is a method for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulation of the parameters values. 

Plot the `looic` to compare models:

```{r bayesian_model_comparison, echo=TRUE, warning=FALSE}
loo.relevant.deps <- c(loo.model.Poisson[3], loo.model.NB[3], loo.model.NB2[3], loo.model.NB.hier[3])
loo.all.deps<-c(loo.model.Poisson.complete[3], loo.NB.complete[3], loo.model.NB2.complete[3], loo.model.NB.hier.complete[3])

sort.loo.relevent.deps<-sort.int(loo.relevant.deps, index.return = TRUE)$x
sort.loo.all.deps<- sort.int(loo.all.deps, index.return = TRUE)$x


par(xaxt="n", mfrow=c(1,2))
plot(sort.loo.relevent.deps, type="b", xlab="", ylab="LOOIC", main="Relevant departments")
par(xaxt="s")
axis(1, c(1:4), c("Poisson", "NB-sl", "NB-ml", 
                  "hier")[sort.int(loo.relevant.deps,
                    index.return = TRUE)$ix],
                    las=2)

par(xaxt="n")
plot(sort.loo.all.deps, type="b", xlab="", ylab="LOOIC", main="All departments")
par(xaxt="s")
axis(1, c(1:4), c("Poisson", "NB-sl", "NB-ml", 
                  "hier")[sort.int(loo.all.deps,
                    index.return = TRUE)$ix],
                    las=2)
```

## Reference

At the moment I'm using as a reference the book `Hierarchical_Models.pdf` in the folder `books`.. and a lot of Google!
<!-- knitr::knit("first_analysis.Rmd", tangle = TRUE, output ="first_analysis.R") -->
